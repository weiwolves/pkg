// Code generated by codegen. DO NOT EDIT.
// Generated by sql/dmlgen. DO NOT EDIT.
// +build !ignore
// +build !ignored

package dmltestgenerated

import (
	"context"
	"database/sql"
	"fmt"
	"io"
	"time"

	"github.com/corestoreio/errors"
	"github.com/weiwolves/pkg/sql/ddl"
	"github.com/weiwolves/pkg/sql/dml"
	"github.com/weiwolves/pkg/storage/null"
	"github.com/weiwolves/pkg/util/cstrace"
	"go.opentelemetry.io/otel/api/trace"
)

const (
	TableNameCatalogProductIndexEAVDecimalIDX = "catalog_product_index_eav_decimal_idx"
	TableNameCoreConfiguration                = "core_configuration"
	TableNameCustomerAddressEntity            = "customer_address_entity"
	TableNameCustomerEntity                   = "customer_entity"
	TableNameDmlgenTypes                      = "dmlgen_types"
	TableNameSalesOrderStatusState            = "sales_order_status_state"
	TableNameViewCustomerAutoIncrement        = "view_customer_auto_increment"
	TableNameViewCustomerNoAutoIncrement      = "view_customer_no_auto_increment"
)

// DBMOption provides various options to the DBM object.
type DBMOption struct {
	Trace                                     trace.Tracer
	TableOptions                              []ddl.TableOption // gets applied at the beginning
	TableOptionsAfter                         []ddl.TableOption // gets applied at the end
	InitSelectFn                              func(*dml.Select) *dml.Select
	InitUpdateFn                              func(*dml.Update) *dml.Update
	InitDeleteFn                              func(*dml.Delete) *dml.Delete
	InitInsertFn                              func(*dml.Insert) *dml.Insert
	eventCatalogProductIndexEAVDecimalIDXFunc [dml.EventFlagMax][]func(context.Context, *CatalogProductIndexEAVDecimalIDXes, *CatalogProductIndexEAVDecimalIDX) error
	eventCoreConfigurationFunc                [dml.EventFlagMax][]func(context.Context, *CoreConfigurations, *CoreConfiguration) error
	eventCustomerAddressEntityFunc            [dml.EventFlagMax][]func(context.Context, *CustomerAddressEntities, *CustomerAddressEntity) error
	eventCustomerEntityFunc                   [dml.EventFlagMax][]func(context.Context, *CustomerEntities, *CustomerEntity) error
	eventDmlgenTypesFunc                      [dml.EventFlagMax][]func(context.Context, *DmlgenTypesCollection, *DmlgenTypes) error
	eventSalesOrderStatusStateFunc            [dml.EventFlagMax][]func(context.Context, *SalesOrderStatusStates, *SalesOrderStatusState) error
	eventViewCustomerAutoIncrementFunc        [dml.EventFlagMax][]func(context.Context, *ViewCustomerAutoIncrements, *ViewCustomerAutoIncrement) error
	eventViewCustomerNoAutoIncrementFunc      [dml.EventFlagMax][]func(context.Context, *ViewCustomerNoAutoIncrements, *ViewCustomerNoAutoIncrement) error
}

// AddEventCatalogProductIndexEAVDecimalIDX adds a specific defined event call
// back to the DBM.
// It panics if the event argument is larger than dml.EventFlagMax.
func (o *DBMOption) AddEventCatalogProductIndexEAVDecimalIDX(event dml.EventFlag, fn func(context.Context, *CatalogProductIndexEAVDecimalIDXes, *CatalogProductIndexEAVDecimalIDX) error) *DBMOption {
	o.eventCatalogProductIndexEAVDecimalIDXFunc[event] = append(o.eventCatalogProductIndexEAVDecimalIDXFunc[event], fn)
	return o
}

// AddEventCoreConfiguration adds a specific defined event call back to the DBM.
// It panics if the event argument is larger than dml.EventFlagMax.
func (o *DBMOption) AddEventCoreConfiguration(event dml.EventFlag, fn func(context.Context, *CoreConfigurations, *CoreConfiguration) error) *DBMOption {
	o.eventCoreConfigurationFunc[event] = append(o.eventCoreConfigurationFunc[event], fn)
	return o
}

// AddEventCustomerAddressEntity adds a specific defined event call back to the
// DBM.
// It panics if the event argument is larger than dml.EventFlagMax.
func (o *DBMOption) AddEventCustomerAddressEntity(event dml.EventFlag, fn func(context.Context, *CustomerAddressEntities, *CustomerAddressEntity) error) *DBMOption {
	o.eventCustomerAddressEntityFunc[event] = append(o.eventCustomerAddressEntityFunc[event], fn)
	return o
}

// AddEventCustomerEntity adds a specific defined event call back to the DBM.
// It panics if the event argument is larger than dml.EventFlagMax.
func (o *DBMOption) AddEventCustomerEntity(event dml.EventFlag, fn func(context.Context, *CustomerEntities, *CustomerEntity) error) *DBMOption {
	o.eventCustomerEntityFunc[event] = append(o.eventCustomerEntityFunc[event], fn)
	return o
}

// AddEventDmlgenTypes adds a specific defined event call back to the DBM.
// It panics if the event argument is larger than dml.EventFlagMax.
func (o *DBMOption) AddEventDmlgenTypes(event dml.EventFlag, fn func(context.Context, *DmlgenTypesCollection, *DmlgenTypes) error) *DBMOption {
	o.eventDmlgenTypesFunc[event] = append(o.eventDmlgenTypesFunc[event], fn)
	return o
}

// AddEventSalesOrderStatusState adds a specific defined event call back to the
// DBM.
// It panics if the event argument is larger than dml.EventFlagMax.
func (o *DBMOption) AddEventSalesOrderStatusState(event dml.EventFlag, fn func(context.Context, *SalesOrderStatusStates, *SalesOrderStatusState) error) *DBMOption {
	o.eventSalesOrderStatusStateFunc[event] = append(o.eventSalesOrderStatusStateFunc[event], fn)
	return o
}

// AddEventViewCustomerAutoIncrement adds a specific defined event call back to
// the DBM.
// It panics if the event argument is larger than dml.EventFlagMax.
func (o *DBMOption) AddEventViewCustomerAutoIncrement(event dml.EventFlag, fn func(context.Context, *ViewCustomerAutoIncrements, *ViewCustomerAutoIncrement) error) *DBMOption {
	o.eventViewCustomerAutoIncrementFunc[event] = append(o.eventViewCustomerAutoIncrementFunc[event], fn)
	return o
}

// AddEventViewCustomerNoAutoIncrement adds a specific defined event call back to
// the DBM.
// It panics if the event argument is larger than dml.EventFlagMax.
func (o *DBMOption) AddEventViewCustomerNoAutoIncrement(event dml.EventFlag, fn func(context.Context, *ViewCustomerNoAutoIncrements, *ViewCustomerNoAutoIncrement) error) *DBMOption {
	o.eventViewCustomerNoAutoIncrementFunc[event] = append(o.eventViewCustomerNoAutoIncrementFunc[event], fn)
	return o
}

// DBM defines the DataBaseManagement object for the tables
// catalog_product_index_eav_decimal_idx, core_configuration,
// customer_address_entity, customer_entity, dmlgen_types,
// sales_order_status_state, view_customer_auto_increment,
// view_customer_no_auto_increment
type DBM struct {
	*ddl.Tables
	option DBMOption
}

func (dbm DBM) eventCatalogProductIndexEAVDecimalIDXFunc(ctx context.Context, ef dml.EventFlag, ec *CatalogProductIndexEAVDecimalIDXes, e *CatalogProductIndexEAVDecimalIDX) error {
	if len(dbm.option.eventCatalogProductIndexEAVDecimalIDXFunc[ef]) == 0 || dml.EventsAreSkipped(ctx) {
		return nil
	}
	for _, fn := range dbm.option.eventCatalogProductIndexEAVDecimalIDXFunc[ef] {
		if err := fn(ctx, ec, e); err != nil {
			return errors.WithStack(err)
		}
	}
	return nil
}

func (dbm DBM) eventCoreConfigurationFunc(ctx context.Context, ef dml.EventFlag, ec *CoreConfigurations, e *CoreConfiguration) error {
	if len(dbm.option.eventCoreConfigurationFunc[ef]) == 0 || dml.EventsAreSkipped(ctx) {
		return nil
	}
	for _, fn := range dbm.option.eventCoreConfigurationFunc[ef] {
		if err := fn(ctx, ec, e); err != nil {
			return errors.WithStack(err)
		}
	}
	return nil
}

func (dbm DBM) eventCustomerAddressEntityFunc(ctx context.Context, ef dml.EventFlag, ec *CustomerAddressEntities, e *CustomerAddressEntity) error {
	if len(dbm.option.eventCustomerAddressEntityFunc[ef]) == 0 || dml.EventsAreSkipped(ctx) {
		return nil
	}
	for _, fn := range dbm.option.eventCustomerAddressEntityFunc[ef] {
		if err := fn(ctx, ec, e); err != nil {
			return errors.WithStack(err)
		}
	}
	return nil
}

func (dbm DBM) eventCustomerEntityFunc(ctx context.Context, ef dml.EventFlag, ec *CustomerEntities, e *CustomerEntity) error {
	if len(dbm.option.eventCustomerEntityFunc[ef]) == 0 || dml.EventsAreSkipped(ctx) {
		return nil
	}
	for _, fn := range dbm.option.eventCustomerEntityFunc[ef] {
		if err := fn(ctx, ec, e); err != nil {
			return errors.WithStack(err)
		}
	}
	return nil
}

func (dbm DBM) eventDmlgenTypesFunc(ctx context.Context, ef dml.EventFlag, ec *DmlgenTypesCollection, e *DmlgenTypes) error {
	if len(dbm.option.eventDmlgenTypesFunc[ef]) == 0 || dml.EventsAreSkipped(ctx) {
		return nil
	}
	for _, fn := range dbm.option.eventDmlgenTypesFunc[ef] {
		if err := fn(ctx, ec, e); err != nil {
			return errors.WithStack(err)
		}
	}
	return nil
}

func (dbm DBM) eventSalesOrderStatusStateFunc(ctx context.Context, ef dml.EventFlag, ec *SalesOrderStatusStates, e *SalesOrderStatusState) error {
	if len(dbm.option.eventSalesOrderStatusStateFunc[ef]) == 0 || dml.EventsAreSkipped(ctx) {
		return nil
	}
	for _, fn := range dbm.option.eventSalesOrderStatusStateFunc[ef] {
		if err := fn(ctx, ec, e); err != nil {
			return errors.WithStack(err)
		}
	}
	return nil
}

func (dbm DBM) eventViewCustomerAutoIncrementFunc(ctx context.Context, ef dml.EventFlag, ec *ViewCustomerAutoIncrements, e *ViewCustomerAutoIncrement) error {
	if len(dbm.option.eventViewCustomerAutoIncrementFunc[ef]) == 0 || dml.EventsAreSkipped(ctx) {
		return nil
	}
	for _, fn := range dbm.option.eventViewCustomerAutoIncrementFunc[ef] {
		if err := fn(ctx, ec, e); err != nil {
			return errors.WithStack(err)
		}
	}
	return nil
}

func (dbm DBM) eventViewCustomerNoAutoIncrementFunc(ctx context.Context, ef dml.EventFlag, ec *ViewCustomerNoAutoIncrements, e *ViewCustomerNoAutoIncrement) error {
	if len(dbm.option.eventViewCustomerNoAutoIncrementFunc[ef]) == 0 || dml.EventsAreSkipped(ctx) {
		return nil
	}
	for _, fn := range dbm.option.eventViewCustomerNoAutoIncrementFunc[ef] {
		if err := fn(ctx, ec, e); err != nil {
			return errors.WithStack(err)
		}
	}
	return nil
}

// NewDBManager returns a goified version of the MySQL/MariaDB table schema for
// the tables:  catalog_product_index_eav_decimal_idx, core_configuration,
// customer_address_entity, customer_entity, dmlgen_types,
// sales_order_status_state, view_customer_auto_increment,
// view_customer_no_auto_increment Auto generated by dmlgen.
func NewDBManager(ctx context.Context, dbmo *DBMOption) (*DBM, error) {
	tbls, err := ddl.NewTables(append([]ddl.TableOption{ddl.WithCreateTable(ctx, TableNameCatalogProductIndexEAVDecimalIDX, "", TableNameCoreConfiguration, "", TableNameCustomerAddressEntity, "", TableNameCustomerEntity, "", TableNameDmlgenTypes, "", TableNameSalesOrderStatusState, "", TableNameViewCustomerAutoIncrement, "", TableNameViewCustomerNoAutoIncrement, "")}, dbmo.TableOptions...)...)
	if err != nil {
		return nil, errors.WithStack(err)
	}
	if dbmo.InitSelectFn == nil {
		dbmo.InitSelectFn = func(s *dml.Select) *dml.Select { return s }
	}
	if dbmo.InitUpdateFn == nil {
		dbmo.InitUpdateFn = func(s *dml.Update) *dml.Update { return s }
	}
	if dbmo.InitDeleteFn == nil {
		dbmo.InitDeleteFn = func(s *dml.Delete) *dml.Delete { return s }
	}
	if dbmo.InitInsertFn == nil {
		dbmo.InitInsertFn = func(s *dml.Insert) *dml.Insert { return s }
	}
	err = tbls.Options(
		ddl.WithQueryDBR("CatalogProductIndexEAVDecimalIDXesSelectAll", dbmo.InitSelectFn(tbls.MustTable(TableNameCatalogProductIndexEAVDecimalIDX).Select("*")).WithDBR()),
		ddl.WithQueryDBR("CatalogProductIndexEAVDecimalIDXesSelectByPK", dbmo.InitSelectFn(tbls.MustTable(TableNameCatalogProductIndexEAVDecimalIDX).Select("*")).Where(
			dml.Columns(`entity_id`, `attribute_id`, `store_id`, `source_id`).In().Tuples(),
		).WithDBR().Interpolate()),
		ddl.WithQueryDBR("CatalogProductIndexEAVDecimalIDXSelectByPK", dbmo.InitSelectFn(tbls.MustTable(TableNameCatalogProductIndexEAVDecimalIDX).Select("*")).Where(
			dml.Columns(`entity_id`, `attribute_id`, `store_id`, `source_id`).Equal().Tuples(),
		).WithDBR().Interpolate()),
		ddl.WithQueryDBR("CatalogProductIndexEAVDecimalIDXUpdateByPK", dbmo.InitUpdateFn(tbls.MustTable(TableNameCatalogProductIndexEAVDecimalIDX).Update().Where(
			dml.Columns(`entity_id`, `attribute_id`, `store_id`, `source_id`).In().Tuples(),
		)).WithDBR()),
		ddl.WithQueryDBR("CatalogProductIndexEAVDecimalIDXDeleteByPK", dbmo.InitDeleteFn(tbls.MustTable(TableNameCatalogProductIndexEAVDecimalIDX).Delete().Where(
			dml.Columns(`entity_id`, `attribute_id`, `store_id`, `source_id`).In().Tuples(),
		)).WithDBR().Interpolate()),
		ddl.WithQueryDBR("CatalogProductIndexEAVDecimalIDXInsert", dbmo.InitInsertFn(tbls.MustTable(TableNameCatalogProductIndexEAVDecimalIDX).Insert()).WithDBR()),
		ddl.WithQueryDBR("CatalogProductIndexEAVDecimalIDXUpsertByPK", dbmo.InitInsertFn(tbls.MustTable(TableNameCatalogProductIndexEAVDecimalIDX).Insert()).OnDuplicateKey().WithDBR()),
		ddl.WithQueryDBR("CoreConfigurationsSelectAll", dbmo.InitSelectFn(tbls.MustTable(TableNameCoreConfiguration).Select("*")).WithDBR()),
		ddl.WithQueryDBR("CoreConfigurationsSelectByPK", dbmo.InitSelectFn(tbls.MustTable(TableNameCoreConfiguration).Select("*")).Where(
			dml.Column(`config_id`).In().PlaceHolder(),
		).WithDBR().Interpolate()),
		ddl.WithQueryDBR("CoreConfigurationSelectByPK", dbmo.InitSelectFn(tbls.MustTable(TableNameCoreConfiguration).Select("*")).Where(
			dml.Column(`config_id`).Equal().PlaceHolder(),
		).WithDBR().Interpolate()),
		ddl.WithQueryDBR("CoreConfigurationUpdateByPK", dbmo.InitUpdateFn(tbls.MustTable(TableNameCoreConfiguration).Update().Where(
			dml.Column(`config_id`).In().PlaceHolder(),
		)).WithDBR()),
		ddl.WithQueryDBR("CoreConfigurationDeleteByPK", dbmo.InitDeleteFn(tbls.MustTable(TableNameCoreConfiguration).Delete().Where(
			dml.Column(`config_id`).In().PlaceHolder(),
		)).WithDBR().Interpolate()),
		ddl.WithQueryDBR("CoreConfigurationInsert", dbmo.InitInsertFn(tbls.MustTable(TableNameCoreConfiguration).Insert()).WithDBR()),
		ddl.WithQueryDBR("CoreConfigurationUpsertByPK", dbmo.InitInsertFn(tbls.MustTable(TableNameCoreConfiguration).Insert()).OnDuplicateKey().WithDBR()),
		ddl.WithQueryDBR("CustomerAddressEntitiesSelectAll", dbmo.InitSelectFn(tbls.MustTable(TableNameCustomerAddressEntity).Select("*")).WithDBR()),
		ddl.WithQueryDBR("CustomerAddressEntitiesSelectByPK", dbmo.InitSelectFn(tbls.MustTable(TableNameCustomerAddressEntity).Select("*")).Where(
			dml.Column(`entity_id`).In().PlaceHolder(),
		).WithDBR().Interpolate()),
		ddl.WithQueryDBR("CustomerAddressEntitySelectByPK", dbmo.InitSelectFn(tbls.MustTable(TableNameCustomerAddressEntity).Select("*")).Where(
			dml.Column(`entity_id`).Equal().PlaceHolder(),
		).WithDBR().Interpolate()),
		ddl.WithQueryDBR("CustomerAddressEntityUpdateByPK", dbmo.InitUpdateFn(tbls.MustTable(TableNameCustomerAddressEntity).Update().Where(
			dml.Column(`entity_id`).In().PlaceHolder(),
		)).WithDBR()),
		ddl.WithQueryDBR("CustomerAddressEntityDeleteByPK", dbmo.InitDeleteFn(tbls.MustTable(TableNameCustomerAddressEntity).Delete().Where(
			dml.Column(`entity_id`).In().PlaceHolder(),
		)).WithDBR().Interpolate()),
		ddl.WithQueryDBR("CustomerAddressEntityInsert", dbmo.InitInsertFn(tbls.MustTable(TableNameCustomerAddressEntity).Insert()).WithDBR()),
		ddl.WithQueryDBR("CustomerAddressEntityUpsertByPK", dbmo.InitInsertFn(tbls.MustTable(TableNameCustomerAddressEntity).Insert()).OnDuplicateKey().WithDBR()),
		ddl.WithQueryDBR("CustomerEntitiesSelectAll", dbmo.InitSelectFn(tbls.MustTable(TableNameCustomerEntity).Select("*")).WithDBR()),
		ddl.WithQueryDBR("CustomerEntitiesSelectByPK", dbmo.InitSelectFn(tbls.MustTable(TableNameCustomerEntity).Select("*")).Where(
			dml.Column(`entity_id`).In().PlaceHolder(),
		).WithDBR().Interpolate()),
		ddl.WithQueryDBR("CustomerEntitySelectByPK", dbmo.InitSelectFn(tbls.MustTable(TableNameCustomerEntity).Select("*")).Where(
			dml.Column(`entity_id`).Equal().PlaceHolder(),
		).WithDBR().Interpolate()),
		ddl.WithQueryDBR("CustomerEntityUpdateByPK", dbmo.InitUpdateFn(tbls.MustTable(TableNameCustomerEntity).Update().Where(
			dml.Column(`entity_id`).In().PlaceHolder(),
		)).WithDBR()),
		ddl.WithQueryDBR("CustomerEntityDeleteByPK", dbmo.InitDeleteFn(tbls.MustTable(TableNameCustomerEntity).Delete().Where(
			dml.Column(`entity_id`).In().PlaceHolder(),
		)).WithDBR().Interpolate()),
		ddl.WithQueryDBR("CustomerEntityInsert", dbmo.InitInsertFn(tbls.MustTable(TableNameCustomerEntity).Insert()).WithDBR()),
		ddl.WithQueryDBR("CustomerEntityUpsertByPK", dbmo.InitInsertFn(tbls.MustTable(TableNameCustomerEntity).Insert()).OnDuplicateKey().WithDBR()),
		ddl.WithQueryDBR("DmlgenTypesCollectionSelectAll", dbmo.InitSelectFn(tbls.MustTable(TableNameDmlgenTypes).Select("*")).WithDBR()),
		ddl.WithQueryDBR("DmlgenTypesCollectionSelectByPK", dbmo.InitSelectFn(tbls.MustTable(TableNameDmlgenTypes).Select("*")).Where(
			dml.Column(`id`).In().PlaceHolder(),
		).WithDBR().Interpolate()),
		ddl.WithQueryDBR("DmlgenTypesSelectByPK", dbmo.InitSelectFn(tbls.MustTable(TableNameDmlgenTypes).Select("*")).Where(
			dml.Column(`id`).Equal().PlaceHolder(),
		).WithDBR().Interpolate()),
		ddl.WithQueryDBR("DmlgenTypesUpdateByPK", dbmo.InitUpdateFn(tbls.MustTable(TableNameDmlgenTypes).Update().Where(
			dml.Column(`id`).In().PlaceHolder(),
		)).WithDBR()),
		ddl.WithQueryDBR("DmlgenTypesDeleteByPK", dbmo.InitDeleteFn(tbls.MustTable(TableNameDmlgenTypes).Delete().Where(
			dml.Column(`id`).In().PlaceHolder(),
		)).WithDBR().Interpolate()),
		ddl.WithQueryDBR("DmlgenTypesInsert", dbmo.InitInsertFn(tbls.MustTable(TableNameDmlgenTypes).Insert()).WithDBR()),
		ddl.WithQueryDBR("DmlgenTypesUpsertByPK", dbmo.InitInsertFn(tbls.MustTable(TableNameDmlgenTypes).Insert()).OnDuplicateKey().WithDBR()),
		ddl.WithQueryDBR("SalesOrderStatusStatesSelectAll", dbmo.InitSelectFn(tbls.MustTable(TableNameSalesOrderStatusState).Select("*")).WithDBR()),
		ddl.WithQueryDBR("SalesOrderStatusStatesSelectByPK", dbmo.InitSelectFn(tbls.MustTable(TableNameSalesOrderStatusState).Select("*")).Where(
			dml.Columns(`status`, `state`).In().Tuples(),
		).WithDBR().Interpolate()),
		ddl.WithQueryDBR("SalesOrderStatusStateSelectByPK", dbmo.InitSelectFn(tbls.MustTable(TableNameSalesOrderStatusState).Select("*")).Where(
			dml.Columns(`status`, `state`).Equal().Tuples(),
		).WithDBR().Interpolate()),
		ddl.WithQueryDBR("SalesOrderStatusStateUpdateByPK", dbmo.InitUpdateFn(tbls.MustTable(TableNameSalesOrderStatusState).Update().Where(
			dml.Columns(`status`, `state`).In().Tuples(),
		)).WithDBR()),
		ddl.WithQueryDBR("SalesOrderStatusStateDeleteByPK", dbmo.InitDeleteFn(tbls.MustTable(TableNameSalesOrderStatusState).Delete().Where(
			dml.Columns(`status`, `state`).In().Tuples(),
		)).WithDBR().Interpolate()),
		ddl.WithQueryDBR("SalesOrderStatusStateInsert", dbmo.InitInsertFn(tbls.MustTable(TableNameSalesOrderStatusState).Insert()).WithDBR()),
		ddl.WithQueryDBR("SalesOrderStatusStateUpsertByPK", dbmo.InitInsertFn(tbls.MustTable(TableNameSalesOrderStatusState).Insert()).OnDuplicateKey().WithDBR()),
		ddl.WithQueryDBR("ViewCustomerAutoIncrementsSelectAll", dbmo.InitSelectFn(tbls.MustTable(TableNameViewCustomerAutoIncrement).Select("*")).WithDBR()),
		ddl.WithQueryDBR("ViewCustomerAutoIncrementsSelectByPK", dbmo.InitSelectFn(tbls.MustTable(TableNameViewCustomerAutoIncrement).Select("*")).Where(
			dml.Column(`ce_entity_id`).In().PlaceHolder(),
		).WithDBR().Interpolate()),
		ddl.WithQueryDBR("ViewCustomerAutoIncrementSelectByPK", dbmo.InitSelectFn(tbls.MustTable(TableNameViewCustomerAutoIncrement).Select("*")).Where(
			dml.Column(`ce_entity_id`).Equal().PlaceHolder(),
		).WithDBR().Interpolate()),
	)
	if err != nil {
		return nil, err
	}
	if err := tbls.Options(dbmo.TableOptionsAfter...); err != nil {
		return nil, err
	}
	if dbmo.Trace == nil {
		dbmo.Trace = trace.NoopTracer{}
	}
	return &DBM{Tables: tbls, option: *dbmo}, nil
}

// CatalogProductIndexEAVDecimalIDX represents a single row for DB table
// catalog_product_index_eav_decimal_idx. Auto generated.
// Table comment: Catalog Product EAV Decimal Indexer Index Table
type CatalogProductIndexEAVDecimalIDX struct {
	EntityID    uint32       // entity_id int(10) unsigned NOT NULL PRI   "Entity ID"
	AttributeID uint32       // attribute_id smallint(5) unsigned NOT NULL PRI   "Attribute ID"
	StoreID     uint32       // store_id smallint(5) unsigned NOT NULL PRI   "Store ID"
	SourceID    uint32       // source_id int(10) unsigned NOT NULL PRI DEFAULT '0'  "Original entity Id for attribute value"
	Value       null.Decimal // value decimal(12,4) NOT NULL MUL   "Value"
}

// Copy copies the struct and returns a new pointer. TODO use deepcopy tool to
// generate code afterwards
func (e *CatalogProductIndexEAVDecimalIDX) Copy() *CatalogProductIndexEAVDecimalIDX {
	e2 := new(CatalogProductIndexEAVDecimalIDX)
	*e2 = *e // for now a shallow copy
	return e2
}

// MapColumns implements interface ColumnMapper only partially. Auto generated.
func (e *CatalogProductIndexEAVDecimalIDX) MapColumns(cm *dml.ColumnMap) error {
	if cm.Mode() == dml.ColumnMapEntityReadAll {
		return cm.Uint32(&e.EntityID).Uint32(&e.AttributeID).Uint32(&e.StoreID).Uint32(&e.SourceID).Decimal(&e.Value).Err()
	}
	for cm.Next() {
		switch c := cm.Column(); c {
		case "entity_id":
			cm.Uint32(&e.EntityID)
		case "attribute_id":
			cm.Uint32(&e.AttributeID)
		case "store_id":
			cm.Uint32(&e.StoreID)
		case "source_id":
			cm.Uint32(&e.SourceID)
		case "value":
			cm.Decimal(&e.Value)
		default:
			return errors.NotFound.Newf("[dmltestgenerated] CatalogProductIndexEAVDecimalIDX Column %q not found", c)
		}
	}
	return errors.WithStack(cm.Err())
}

func (e *CatalogProductIndexEAVDecimalIDX) Load(ctx context.Context, dbm *DBM, entityID uint32, attributeID uint32, storeID uint32, sourceID uint32, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CatalogProductIndexEAVDecimalIDXSelectByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return errors.NotValid.Newf("CatalogProductIndexEAVDecimalIDX can't be nil")
	}
	// put the IDs entityID,attributeID,storeID,sourceID into the context as value to search for a cache entry in the event function.
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagBeforeSelect, nil, e); err != nil {
		return errors.WithStack(err)
	}
	if e.IsSet() {
		return nil // might return data from cache
	}
	if _, err = dbm.CachedQuery("CatalogProductIndexEAVDecimalIDXSelectByPK").ApplyCallBacks(opts...).Load(ctx, e, entityID, attributeID, storeID, sourceID); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagAfterSelect, nil, e))
}

func (e *CatalogProductIndexEAVDecimalIDX) Delete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CatalogProductIndexEAVDecimalIDXDeleteByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CatalogProductIndexEAVDecimalIDX can't be nil")
	}
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagBeforeDelete, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CatalogProductIndexEAVDecimalIDXDeleteByPK").ApplyCallBacks(opts...).ExecContext(ctx, e.EntityID, e.AttributeID, e.StoreID, e.SourceID); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagAfterDelete, nil, e)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CatalogProductIndexEAVDecimalIDX) Update(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CatalogProductIndexEAVDecimalIDXUpdateByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CatalogProductIndexEAVDecimalIDX can't be nil")
	}
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagBeforeUpdate, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CatalogProductIndexEAVDecimalIDXUpdateByPK").ApplyCallBacks(opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagAfterUpdate, nil, e)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CatalogProductIndexEAVDecimalIDX) Insert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CatalogProductIndexEAVDecimalIDXInsert")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CatalogProductIndexEAVDecimalIDX can't be nil")
	}
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagBeforeInsert, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CatalogProductIndexEAVDecimalIDXInsert").ApplyCallBacks(opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagAfterInsert, nil, e)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CatalogProductIndexEAVDecimalIDX) Upsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CatalogProductIndexEAVDecimalIDXUpsertByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CatalogProductIndexEAVDecimalIDX can't be nil")
	}
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagBeforeUpsert, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CatalogProductIndexEAVDecimalIDXUpsertByPK").ApplyCallBacks(opts...).ExecContext(ctx, dml.Qualify("", e)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagAfterUpsert, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

// Empty empties all the fields of the current object. Also known as Reset.
func (e *CatalogProductIndexEAVDecimalIDX) Empty() *CatalogProductIndexEAVDecimalIDX {
	*e = CatalogProductIndexEAVDecimalIDX{}
	return e
}

// IsSet returns true if the entity has non-empty primary keys.
func (e *CatalogProductIndexEAVDecimalIDX) IsSet() bool {
	return e.EntityID > 0 && e.AttributeID > 0 && e.StoreID > 0 && e.SourceID > 0
}

// This variable can be set in another file to provide a custom validator.
var validateCatalogProductIndexEAVDecimalIDX func(*CatalogProductIndexEAVDecimalIDX) error

// Validate runs internal consistency tests.
func (e *CatalogProductIndexEAVDecimalIDX) Validate() error {
	if e == nil {
		return errors.NotValid.Newf("Type %T cannot be nil", e)
	}
	if validateCatalogProductIndexEAVDecimalIDX != nil {
		return validateCatalogProductIndexEAVDecimalIDX(e)
	}
	return nil
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (e *CatalogProductIndexEAVDecimalIDX) WriteTo(w io.Writer) (n int64, err error) {
	// for now this printing is good enough. If you need better swap out with your code.
	n2, err := fmt.Fprint(w,
		"entity_id:", e.EntityID, "\n",
		"attribute_id:", e.AttributeID, "\n",
		"store_id:", e.StoreID, "\n",
		"source_id:", e.SourceID, "\n",
		"value:", e.Value, "\n",
	)
	return int64(n2), err
}

// CatalogProductIndexEAVDecimalIDXes represents a collection type for DB table
// catalog_product_index_eav_decimal_idx
// Not thread safe. Auto generated.
type CatalogProductIndexEAVDecimalIDXes struct {
	Data []*CatalogProductIndexEAVDecimalIDX `json:"data,omitempty"`
}

// NewCatalogProductIndexEAVDecimalIDXes  creates a new initialized collection.
// Auto generated.
func NewCatalogProductIndexEAVDecimalIDXes() *CatalogProductIndexEAVDecimalIDXes {
	return &CatalogProductIndexEAVDecimalIDXes{
		Data: make([]*CatalogProductIndexEAVDecimalIDX, 0, 5),
	}
}

// Append will add a new item at the end of * CatalogProductIndexEAVDecimalIDXes
// . Auto generated via dmlgen.
func (cc *CatalogProductIndexEAVDecimalIDXes) Append(n ...*CatalogProductIndexEAVDecimalIDX) *CatalogProductIndexEAVDecimalIDXes {
	cc.Data = append(cc.Data, n...)
	return cc
}

// Cut will remove items i through j-1. Auto generated via dmlgen.
func (cc *CatalogProductIndexEAVDecimalIDXes) Cut(i, j int) *CatalogProductIndexEAVDecimalIDXes {
	z := cc.Data // copy slice header
	copy(z[i:], z[j:])
	for k, n := len(z)-j+i, len(z); k < n; k++ {
		z[k] = nil // this avoids the memory leak
	}
	z = z[:len(z)-j+i]
	cc.Data = z
	return cc
}

func (cc *CatalogProductIndexEAVDecimalIDXes) scanColumns(cm *dml.ColumnMap, e *CatalogProductIndexEAVDecimalIDX, idx uint64) error {
	if err := e.MapColumns(cm); err != nil {
		return errors.WithStack(err)
	}
	// this function might get extended.
	return nil
}

// MapColumns implements dml.ColumnMapper interface. Auto generated.
func (cc *CatalogProductIndexEAVDecimalIDXes) MapColumns(cm *dml.ColumnMap) error {
	switch m := cm.Mode(); m {
	case dml.ColumnMapEntityReadAll, dml.ColumnMapEntityReadSet:
		for i, e := range cc.Data {
			if err := cc.scanColumns(cm, e, uint64(i)); err != nil {
				return errors.WithStack(err)
			}
		}
	case dml.ColumnMapScan:
		if cm.Count == 0 {
			cc.Data = cc.Data[:0]
		}
		e := new(CatalogProductIndexEAVDecimalIDX)
		if err := cc.scanColumns(cm, e, cm.Count); err != nil {
			return errors.WithStack(err)
		}
		cc.Data = append(cc.Data, e)
	case dml.ColumnMapCollectionReadSet:
		for cm.Next() {
			switch c := cm.Column(); c {
			case "entity_id":
				cm = cm.Uint32s(cc.EntityIDs()...)
			case "attribute_id":
				cm = cm.Uint32s(cc.AttributeIDs()...)
			case "store_id":
				cm = cm.Uint32s(cc.StoreIDs()...)
			case "source_id":
				cm = cm.Uint32s(cc.SourceIDs()...)
			default:
				return errors.NotFound.Newf("[dmltestgenerated] CatalogProductIndexEAVDecimalIDXes Column %q not found", c)
			}
		} // end for cm.Next

	default:
		return errors.NotSupported.Newf("[dmltestgenerated] Unknown Mode: %q", string(m))
	}
	return cm.Err()
}

type CatalogProductIndexEAVDecimalIDXesDBLoadArgs struct {
	EntityID    uint32
	AttributeID uint32
	StoreID     uint32
	SourceID    uint32
}

func (cc *CatalogProductIndexEAVDecimalIDXes) DBLoad(ctx context.Context, dbm *DBM, pkIDs []CatalogProductIndexEAVDecimalIDXesDBLoadArgs, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CatalogProductIndexEAVDecimalIDXesDBLoad")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("CatalogProductIndexEAVDecimalIDX can't be nil")
	}
	// put the IDs EntityID,AttributeID,StoreID,SourceID into the context as value to search for a cache entry in the event function.
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagBeforeSelect, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	if cc.Data != nil {
		return nil // might return data from cache
	}
	cacheKey := "CatalogProductIndexEAVDecimalIDXesSelectAll"
	var args []interface{}
	if len(pkIDs) > 0 {
		args = make([]interface{}, 0, len(pkIDs)*4)
		for _, pk := range pkIDs {
			args = append(args, pk.EntityID)
			args = append(args, pk.AttributeID)
			args = append(args, pk.StoreID)
			args = append(args, pk.SourceID)
		}
		cacheKey = "CatalogProductIndexEAVDecimalIDXesSelectByPK"
	}
	if _, err = dbm.CachedQuery(cacheKey).ApplyCallBacks(opts...).Load(ctx, cc, args...); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagAfterSelect, cc, nil))
}

func (cc *CatalogProductIndexEAVDecimalIDXes) DBDelete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CatalogProductIndexEAVDecimalIDXesDeleteByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("CatalogProductIndexEAVDecimalIDXes can't be nil")
	}
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagBeforeDelete, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CatalogProductIndexEAVDecimalIDXDeleteByPK").ApplyCallBacks(opts...).ExecContext(ctx, dml.Qualify("", cc)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagAfterDelete, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *CatalogProductIndexEAVDecimalIDXes) DBUpdate(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CatalogProductIndexEAVDecimalIDXesUpdateByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("CatalogProductIndexEAVDecimalIDXes can't be nil")
	}
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagBeforeUpdate, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CatalogProductIndexEAVDecimalIDXUpdateByPK").ApplyCallBacks(opts...).ExecContext(ctx, cc); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagAfterUpdate, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *CatalogProductIndexEAVDecimalIDXes) DBInsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CatalogProductIndexEAVDecimalIDXesInsert")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("CatalogProductIndexEAVDecimalIDXes can't be nil")
	}
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagBeforeInsert, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CatalogProductIndexEAVDecimalIDXInsert").ApplyCallBacks(opts...).ExecContext(ctx, cc); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagAfterInsert, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *CatalogProductIndexEAVDecimalIDXes) DBUpsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CatalogProductIndexEAVDecimalIDXesUpsertByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("CatalogProductIndexEAVDecimalIDXes can't be nil")
	}
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagBeforeUpsert, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CatalogProductIndexEAVDecimalIDXUpsertByPK").ApplyCallBacks(opts...).ExecContext(ctx, dml.Qualify("", cc)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCatalogProductIndexEAVDecimalIDXFunc(ctx, dml.EventFlagAfterUpsert, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

// Delete will remove an item from the slice. Auto generated via dmlgen.
func (cc *CatalogProductIndexEAVDecimalIDXes) Delete(i int) *CatalogProductIndexEAVDecimalIDXes {
	z := cc.Data // copy the slice header
	end := len(z) - 1
	cc.Swap(i, end)
	copy(z[i:], z[i+1:])
	z[end] = nil // this should avoid the memory leak
	z = z[:end]
	cc.Data = z
	return cc
}

// Each will run function f on all items in []* CatalogProductIndexEAVDecimalIDX
// . Auto generated via dmlgen.
func (cc *CatalogProductIndexEAVDecimalIDXes) Each(f func(*CatalogProductIndexEAVDecimalIDX)) *CatalogProductIndexEAVDecimalIDXes {
	if cc == nil {
		return nil
	}
	for i := range cc.Data {
		f(cc.Data[i])
	}
	return cc
}

// Filter filters the current slice by predicate f without memory allocation.
// Auto generated via dmlgen.
func (cc *CatalogProductIndexEAVDecimalIDXes) Filter(f func(*CatalogProductIndexEAVDecimalIDX) bool) *CatalogProductIndexEAVDecimalIDXes {
	if cc == nil {
		return nil
	}
	b, i := cc.Data[:0], 0
	for _, e := range cc.Data {
		if f(e) {
			b = append(b, e)
		}
		i++
	}
	for i := len(b); i < len(cc.Data); i++ {
		cc.Data[i] = nil // this should avoid the memory leak
	}
	cc.Data = b
	return cc
}

// Insert will place a new item at position i. Auto generated via dmlgen.
func (cc *CatalogProductIndexEAVDecimalIDXes) Insert(n *CatalogProductIndexEAVDecimalIDX, i int) *CatalogProductIndexEAVDecimalIDXes {
	z := cc.Data // copy the slice header
	z = append(z, &CatalogProductIndexEAVDecimalIDX{})
	copy(z[i+1:], z[i:])
	z[i] = n
	cc.Data = z
	return cc
}

// Swap will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *CatalogProductIndexEAVDecimalIDXes) Swap(i, j int) {
	cc.Data[i], cc.Data[j] = cc.Data[j], cc.Data[i]
}

// Len will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *CatalogProductIndexEAVDecimalIDXes) Len() int {
	if cc == nil {
		return 0
	}
	return len(cc.Data)
}

// EntityIDs returns a slice with the data or appends it to a slice.
// Auto generated.
func (cc *CatalogProductIndexEAVDecimalIDXes) EntityIDs(ret ...uint32) []uint32 {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]uint32, 0, len(cc.Data))
	}
	for _, e := range cc.Data {
		ret = append(ret, e.EntityID)
	}
	return ret
}

// AttributeIDs returns a slice with the data or appends it to a slice.
// Auto generated.
func (cc *CatalogProductIndexEAVDecimalIDXes) AttributeIDs(ret ...uint32) []uint32 {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]uint32, 0, len(cc.Data))
	}
	for _, e := range cc.Data {
		ret = append(ret, e.AttributeID)
	}
	return ret
}

// StoreIDs returns a slice with the data or appends it to a slice.
// Auto generated.
func (cc *CatalogProductIndexEAVDecimalIDXes) StoreIDs(ret ...uint32) []uint32 {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]uint32, 0, len(cc.Data))
	}
	for _, e := range cc.Data {
		ret = append(ret, e.StoreID)
	}
	return ret
}

// SourceIDs returns a slice with the data or appends it to a slice.
// Auto generated.
func (cc *CatalogProductIndexEAVDecimalIDXes) SourceIDs(ret ...uint32) []uint32 {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]uint32, 0, len(cc.Data))
	}
	for _, e := range cc.Data {
		ret = append(ret, e.SourceID)
	}
	return ret
}

// Validate runs internal consistency tests on all items.
func (cc *CatalogProductIndexEAVDecimalIDXes) Validate() (err error) {
	if len(cc.Data) == 0 {
		return nil
	}
	for i, ld := 0, len(cc.Data); i < ld && err == nil; i++ {
		err = cc.Data[i].Validate()
	}
	return
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (cc *CatalogProductIndexEAVDecimalIDXes) WriteTo(w io.Writer) (n int64, err error) {
	for i, d := range cc.Data {
		n2, err := d.WriteTo(w)
		if err != nil {
			return 0, errors.Wrapf(err, "[dmltestgenerated] WriteTo failed at index %d", i)
		}
		n += n2
	}
	return n, nil
}

// CoreConfiguration represents a single row for DB table core_configuration.
// Auto generated.
// Table comment: Config Data
//easyjson:json
type CoreConfiguration struct {
	ConfigID  uint32      `json:"config_id,omitempty" max_len:"10"`  // config_id int(10) unsigned NOT NULL PRI  auto_increment "Id"
	Scope     string      `json:"scope,omitempty" max_len:"8"`       // scope varchar(8) NOT NULL MUL DEFAULT ''default''  "Scope"
	ScopeID   int32       `json:"scope_id" xml:"scope_id"`           // scope_id int(11) NOT NULL  DEFAULT '0'  "Scope Id"
	Expires   null.Time   `json:"expires,omitempty" `                // expires datetime NULL  DEFAULT 'NULL'  "Value expiration time"
	Path      string      `json:"x_path" xml:"y_path" max_len:"255"` // path varchar(255) NOT NULL  DEFAULT ''general''  "Config Path overwritten"
	Value     null.String `json:"value,omitempty" max_len:"65535"`   // value text NULL  DEFAULT 'NULL'  "Value"
	VersionTs time.Time   `json:"version_ts,omitempty" `             // version_ts timestamp(6) NOT NULL   STORED GENERATED "Timestamp Start Versioning"
	VersionTe time.Time   `json:"version_te,omitempty" `             // version_te timestamp(6) NOT NULL PRI  STORED GENERATED "Timestamp End Versioning"
}

// Copy copies the struct and returns a new pointer. TODO use deepcopy tool to
// generate code afterwards
func (e *CoreConfiguration) Copy() *CoreConfiguration {
	e2 := new(CoreConfiguration)
	*e2 = *e // for now a shallow copy
	return e2
}

// AssignLastInsertID updates the increment ID field with the last inserted ID
// from an INSERT operation. Implements dml.InsertIDAssigner. Auto generated.
func (e *CoreConfiguration) AssignLastInsertID(id int64) {
	e.ConfigID = uint32(id)
}

// MapColumns implements interface ColumnMapper only partially. Auto generated.
func (e *CoreConfiguration) MapColumns(cm *dml.ColumnMap) error {
	if cm.Mode() == dml.ColumnMapEntityReadAll {
		return cm.Uint32(&e.ConfigID).String(&e.Scope).Int32(&e.ScopeID).NullTime(&e.Expires).String(&e.Path).NullString(&e.Value).Time(&e.VersionTs).Time(&e.VersionTe).Err()
	}
	for cm.Next() {
		switch c := cm.Column(); c {
		case "config_id":
			cm.Uint32(&e.ConfigID)
		case "scope":
			cm.String(&e.Scope)
		case "scope_id":
			cm.Int32(&e.ScopeID)
		case "expires":
			cm.NullTime(&e.Expires)
		case "path", "storage_location", "config_directory":
			cm.String(&e.Path)
		case "value":
			cm.NullString(&e.Value)
		case "version_ts":
			cm.Time(&e.VersionTs)
		case "version_te":
			cm.Time(&e.VersionTe)
		default:
			return errors.NotFound.Newf("[dmltestgenerated] CoreConfiguration Column %q not found", c)
		}
	}
	return errors.WithStack(cm.Err())
}

func (e *CoreConfiguration) Load(ctx context.Context, dbm *DBM, configID uint32, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CoreConfigurationSelectByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return errors.NotValid.Newf("CoreConfiguration can't be nil")
	}
	// put the IDs configID into the context as value to search for a cache entry in the event function.
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagBeforeSelect, nil, e); err != nil {
		return errors.WithStack(err)
	}
	if e.IsSet() {
		return nil // might return data from cache
	}
	if _, err = dbm.CachedQuery("CoreConfigurationSelectByPK").ApplyCallBacks(opts...).Load(ctx, e, configID); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagAfterSelect, nil, e))
}

func (e *CoreConfiguration) Delete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CoreConfigurationDeleteByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CoreConfiguration can't be nil")
	}
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagBeforeDelete, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CoreConfigurationDeleteByPK").ApplyCallBacks(opts...).ExecContext(ctx, e.ConfigID); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagAfterDelete, nil, e)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CoreConfiguration) Update(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CoreConfigurationUpdateByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CoreConfiguration can't be nil")
	}
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagBeforeUpdate, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CoreConfigurationUpdateByPK").ApplyCallBacks(opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagAfterUpdate, nil, e)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CoreConfiguration) Insert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CoreConfigurationInsert")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CoreConfiguration can't be nil")
	}
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagBeforeInsert, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CoreConfigurationInsert").ApplyCallBacks(opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagAfterInsert, nil, e)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CoreConfiguration) Upsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CoreConfigurationUpsertByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CoreConfiguration can't be nil")
	}
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagBeforeUpsert, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CoreConfigurationUpsertByPK").ApplyCallBacks(opts...).ExecContext(ctx, dml.Qualify("", e)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagAfterUpsert, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

// Empty empties all the fields of the current object. Also known as Reset.
func (e *CoreConfiguration) Empty() *CoreConfiguration { *e = CoreConfiguration{}; return e }

// IsSet returns true if the entity has non-empty primary keys.
func (e *CoreConfiguration) IsSet() bool { return e.ConfigID > 0 }

// This variable can be set in another file to provide a custom validator.
var validateCoreConfiguration func(*CoreConfiguration) error

// Validate runs internal consistency tests.
func (e *CoreConfiguration) Validate() error {
	if e == nil {
		return errors.NotValid.Newf("Type %T cannot be nil", e)
	}
	if validateCoreConfiguration != nil {
		return validateCoreConfiguration(e)
	}
	return nil
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (e *CoreConfiguration) WriteTo(w io.Writer) (n int64, err error) {
	// for now this printing is good enough. If you need better swap out with your code.
	n2, err := fmt.Fprint(w,
		"config_id:", e.ConfigID, "\n",
		"scope:", e.Scope, "\n",
		"scope_id:", e.ScopeID, "\n",
		"expires:", e.Expires, "\n",
		"path:", e.Path, "\n",
		"value:", e.Value, "\n",
		"version_ts:", e.VersionTs, "\n",
		"version_te:", e.VersionTe, "\n",
	)
	return int64(n2), err
}

// CoreConfigurations represents a collection type for DB table
// core_configuration
// Not thread safe. Auto generated.
//easyjson:json
type CoreConfigurations struct {
	Data []*CoreConfiguration `json:"data,omitempty"`
}

// NewCoreConfigurations  creates a new initialized collection. Auto generated.
func NewCoreConfigurations() *CoreConfigurations {
	return &CoreConfigurations{
		Data: make([]*CoreConfiguration, 0, 5),
	}
}

// Append will add a new item at the end of * CoreConfigurations . Auto generated
// via dmlgen.
func (cc *CoreConfigurations) Append(n ...*CoreConfiguration) *CoreConfigurations {
	cc.Data = append(cc.Data, n...)
	return cc
}

// UnmarshalBinary implements encoding.BinaryUnmarshaler.
func (cc *CoreConfigurations) UnmarshalBinary(data []byte) error {
	return cc.Unmarshal(data) // Implemented via github.com/gogo/protobuf
}

// MarshalBinary implements encoding.BinaryMarshaler.
func (cc *CoreConfigurations) MarshalBinary() (data []byte, err error) {
	return cc.Marshal() // Implemented via github.com/gogo/protobuf
}

// Cut will remove items i through j-1. Auto generated via dmlgen.
func (cc *CoreConfigurations) Cut(i, j int) *CoreConfigurations {
	z := cc.Data // copy slice header
	copy(z[i:], z[j:])
	for k, n := len(z)-j+i, len(z); k < n; k++ {
		z[k] = nil // this avoids the memory leak
	}
	z = z[:len(z)-j+i]
	cc.Data = z
	return cc
}

// AssignLastInsertID traverses through the slice and sets an incrementing new ID
// to each entity.
func (cc *CoreConfigurations) AssignLastInsertID(id int64) {
	for i := int64(0); i < int64(len(cc.Data)); i++ {
		cc.Data[i].AssignLastInsertID(id + i)
	}
}

func (cc *CoreConfigurations) scanColumns(cm *dml.ColumnMap, e *CoreConfiguration, idx uint64) error {
	if err := e.MapColumns(cm); err != nil {
		return errors.WithStack(err)
	}
	// this function might get extended.
	return nil
}

// MapColumns implements dml.ColumnMapper interface. Auto generated.
func (cc *CoreConfigurations) MapColumns(cm *dml.ColumnMap) error {
	switch m := cm.Mode(); m {
	case dml.ColumnMapEntityReadAll, dml.ColumnMapEntityReadSet:
		for i, e := range cc.Data {
			if err := cc.scanColumns(cm, e, uint64(i)); err != nil {
				return errors.WithStack(err)
			}
		}
	case dml.ColumnMapScan:
		if cm.Count == 0 {
			cc.Data = cc.Data[:0]
		}
		e := new(CoreConfiguration)
		if err := cc.scanColumns(cm, e, cm.Count); err != nil {
			return errors.WithStack(err)
		}
		cc.Data = append(cc.Data, e)
	case dml.ColumnMapCollectionReadSet:
		for cm.Next() {
			switch c := cm.Column(); c {
			case "config_id":
				cm = cm.Uint32s(cc.ConfigIDs()...)
			default:
				return errors.NotFound.Newf("[dmltestgenerated] CoreConfigurations Column %q not found", c)
			}
		} // end for cm.Next

	default:
		return errors.NotSupported.Newf("[dmltestgenerated] Unknown Mode: %q", string(m))
	}
	return cm.Err()
}

func (cc *CoreConfigurations) DBLoad(ctx context.Context, dbm *DBM, pkIDs []uint32, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CoreConfigurationsDBLoad")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("CoreConfiguration can't be nil")
	}
	// put the IDs ConfigID into the context as value to search for a cache entry in the event function.
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagBeforeSelect, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	if cc.Data != nil {
		return nil // might return data from cache
	}
	if len(pkIDs) > 0 {
		if _, err = dbm.CachedQuery("CoreConfigurationsSelectByPK").ApplyCallBacks(opts...).Load(ctx, cc, pkIDs); err != nil {
			return errors.WithStack(err)
		}
	} else {
		if _, err = dbm.CachedQuery("CoreConfigurationsSelectAll").ApplyCallBacks(opts...).Load(ctx, cc); err != nil {
			return errors.WithStack(err)
		}
	}
	return errors.WithStack(dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagAfterSelect, cc, nil))
}

func (cc *CoreConfigurations) DBDelete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CoreConfigurationsDeleteByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("CoreConfigurations can't be nil")
	}
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagBeforeDelete, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CoreConfigurationDeleteByPK").ApplyCallBacks(opts...).ExecContext(ctx, dml.Qualify("", cc)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagAfterDelete, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *CoreConfigurations) DBUpdate(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CoreConfigurationsUpdateByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("CoreConfigurations can't be nil")
	}
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagBeforeUpdate, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CoreConfigurationUpdateByPK").ApplyCallBacks(opts...).ExecContext(ctx, cc); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagAfterUpdate, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *CoreConfigurations) DBInsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CoreConfigurationsInsert")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("CoreConfigurations can't be nil")
	}
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagBeforeInsert, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CoreConfigurationInsert").ApplyCallBacks(opts...).ExecContext(ctx, cc); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagAfterInsert, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *CoreConfigurations) DBUpsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CoreConfigurationsUpsertByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("CoreConfigurations can't be nil")
	}
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagBeforeUpsert, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CoreConfigurationUpsertByPK").ApplyCallBacks(opts...).ExecContext(ctx, dml.Qualify("", cc)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCoreConfigurationFunc(ctx, dml.EventFlagAfterUpsert, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

// Delete will remove an item from the slice. Auto generated via dmlgen.
func (cc *CoreConfigurations) Delete(i int) *CoreConfigurations {
	z := cc.Data // copy the slice header
	end := len(z) - 1
	cc.Swap(i, end)
	copy(z[i:], z[i+1:])
	z[end] = nil // this should avoid the memory leak
	z = z[:end]
	cc.Data = z
	return cc
}

// Each will run function f on all items in []* CoreConfiguration . Auto
// generated via dmlgen.
func (cc *CoreConfigurations) Each(f func(*CoreConfiguration)) *CoreConfigurations {
	if cc == nil {
		return nil
	}
	for i := range cc.Data {
		f(cc.Data[i])
	}
	return cc
}

// Filter filters the current slice by predicate f without memory allocation.
// Auto generated via dmlgen.
func (cc *CoreConfigurations) Filter(f func(*CoreConfiguration) bool) *CoreConfigurations {
	if cc == nil {
		return nil
	}
	b, i := cc.Data[:0], 0
	for _, e := range cc.Data {
		if f(e) {
			b = append(b, e)
		}
		i++
	}
	for i := len(b); i < len(cc.Data); i++ {
		cc.Data[i] = nil // this should avoid the memory leak
	}
	cc.Data = b
	return cc
}

// Insert will place a new item at position i. Auto generated via dmlgen.
func (cc *CoreConfigurations) Insert(n *CoreConfiguration, i int) *CoreConfigurations {
	z := cc.Data // copy the slice header
	z = append(z, &CoreConfiguration{})
	copy(z[i+1:], z[i:])
	z[i] = n
	cc.Data = z
	return cc
}

// Swap will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *CoreConfigurations) Swap(i, j int) { cc.Data[i], cc.Data[j] = cc.Data[j], cc.Data[i] }

// Len will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *CoreConfigurations) Len() int {
	if cc == nil {
		return 0
	}
	return len(cc.Data)
}

// ConfigIDs returns a slice with the data or appends it to a slice.
// Auto generated.
func (cc *CoreConfigurations) ConfigIDs(ret ...uint32) []uint32 {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]uint32, 0, len(cc.Data))
	}
	for _, e := range cc.Data {
		ret = append(ret, e.ConfigID)
	}
	return ret
}

// Paths belongs to the column "path" and returns a slice or appends to a slice
// only unique values of that column. The values will be filtered internally in a
// Go map. No DB query gets executed. Auto generated.
func (cc *CoreConfigurations) UniquePaths(ret ...string) []string {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]string, 0, len(cc.Data))
	}
	dupCheck := make(map[string]bool, len(cc.Data))
	for _, e := range cc.Data {
		if !dupCheck[e.Path] {
			ret = append(ret, e.Path)
			dupCheck[e.Path] = true
		}
	}
	return ret
}

// Validate runs internal consistency tests on all items.
func (cc *CoreConfigurations) Validate() (err error) {
	if len(cc.Data) == 0 {
		return nil
	}
	for i, ld := 0, len(cc.Data); i < ld && err == nil; i++ {
		err = cc.Data[i].Validate()
	}
	return
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (cc *CoreConfigurations) WriteTo(w io.Writer) (n int64, err error) {
	for i, d := range cc.Data {
		n2, err := d.WriteTo(w)
		if err != nil {
			return 0, errors.Wrapf(err, "[dmltestgenerated] WriteTo failed at index %d", i)
		}
		n += n2
	}
	return n, nil
}

// CustomerAddressEntity represents a single row for DB table
// customer_address_entity. Auto generated.
// Table comment: Customer Address Entity
//easyjson:json
type CustomerAddressEntity struct {
	EntityID          uint32      `max_len:"10"` // entity_id int(10) unsigned NOT NULL PRI  auto_increment "Entity ID"
	IncrementID       null.String `max_len:"50"` // increment_id varchar(50) NULL  DEFAULT 'NULL'  "Increment Id"
	ParentID          null.Uint32 `max_len:"10"` // parent_id int(10) unsigned NULL MUL DEFAULT 'NULL'  "Parent ID"
	CreatedAt         time.Time   // created_at timestamp NOT NULL  DEFAULT 'current_timestamp()'  "Created At"
	UpdatedAt         time.Time   // updated_at timestamp NOT NULL  DEFAULT 'current_timestamp()' on update current_timestamp() "Updated At"
	IsActive          bool        `max_len:"5"`     // is_active smallint(5) unsigned NOT NULL  DEFAULT '1'  "Is Active"
	City              string      `max_len:"255"`   // city varchar(255) NOT NULL    "City"
	Company           null.String `max_len:"255"`   // company varchar(255) NULL  DEFAULT 'NULL'  "Company"
	CountryID         string      `max_len:"255"`   // country_id varchar(255) NOT NULL    "Country"
	Fax               null.String `max_len:"255"`   // fax varchar(255) NULL  DEFAULT 'NULL'  "Fax"
	Firstname         string      `max_len:"255"`   // firstname varchar(255) NOT NULL    "First Name"
	Lastname          string      `max_len:"255"`   // lastname varchar(255) NOT NULL    "Last Name"
	Middlename        null.String `max_len:"255"`   // middlename varchar(255) NULL  DEFAULT 'NULL'  "Middle Name"
	Postcode          null.String `max_len:"255"`   // postcode varchar(255) NULL  DEFAULT 'NULL'  "Zip/Postal Code"
	Prefix            null.String `max_len:"40"`    // prefix varchar(40) NULL  DEFAULT 'NULL'  "Name Prefix"
	Region            null.String `max_len:"255"`   // region varchar(255) NULL  DEFAULT 'NULL'  "State/Province"
	RegionID          null.Uint32 `max_len:"10"`    // region_id int(10) unsigned NULL  DEFAULT 'NULL'  "State/Province"
	Street            string      `max_len:"65535"` // street text NOT NULL    "Street Address"
	Suffix            null.String `max_len:"40"`    // suffix varchar(40) NULL  DEFAULT 'NULL'  "Name Suffix"
	Telephone         string      `max_len:"255"`   // telephone varchar(255) NOT NULL    "Phone Number"
	VatID             null.String `max_len:"255"`   // vat_id varchar(255) NULL  DEFAULT 'NULL'  "VAT number"
	VatIsValid        null.Bool   `max_len:"10"`    // vat_is_valid int(10) unsigned NULL  DEFAULT 'NULL'  "VAT number validity"
	VatRequestDate    null.String `max_len:"255"`   // vat_request_date varchar(255) NULL  DEFAULT 'NULL'  "VAT number validation request date"
	VatRequestID      null.String `max_len:"255"`   // vat_request_id varchar(255) NULL  DEFAULT 'NULL'  "VAT number validation request ID"
	VatRequestSuccess null.Uint32 `max_len:"10"`    // vat_request_success int(10) unsigned NULL  DEFAULT 'NULL'  "VAT number validation request success"
}

// Copy copies the struct and returns a new pointer. TODO use deepcopy tool to
// generate code afterwards
func (e *CustomerAddressEntity) Copy() *CustomerAddressEntity {
	e2 := new(CustomerAddressEntity)
	*e2 = *e // for now a shallow copy
	return e2
}

// AssignLastInsertID updates the increment ID field with the last inserted ID
// from an INSERT operation. Implements dml.InsertIDAssigner. Auto generated.
func (e *CustomerAddressEntity) AssignLastInsertID(id int64) {
	e.EntityID = uint32(id)
}

// MapColumns implements interface ColumnMapper only partially. Auto generated.
func (e *CustomerAddressEntity) MapColumns(cm *dml.ColumnMap) error {
	if cm.Mode() == dml.ColumnMapEntityReadAll {
		return cm.Uint32(&e.EntityID).NullString(&e.IncrementID).NullUint32(&e.ParentID).Time(&e.CreatedAt).Time(&e.UpdatedAt).Bool(&e.IsActive).String(&e.City).NullString(&e.Company).String(&e.CountryID).NullString(&e.Fax).String(&e.Firstname).String(&e.Lastname).NullString(&e.Middlename).NullString(&e.Postcode).NullString(&e.Prefix).NullString(&e.Region).NullUint32(&e.RegionID).String(&e.Street).NullString(&e.Suffix).String(&e.Telephone).NullString(&e.VatID).NullBool(&e.VatIsValid).NullString(&e.VatRequestDate).NullString(&e.VatRequestID).NullUint32(&e.VatRequestSuccess).Err()
	}
	for cm.Next() {
		switch c := cm.Column(); c {
		case "entity_id":
			cm.Uint32(&e.EntityID)
		case "increment_id":
			cm.NullString(&e.IncrementID)
		case "parent_id":
			cm.NullUint32(&e.ParentID)
		case "created_at":
			cm.Time(&e.CreatedAt)
		case "updated_at":
			cm.Time(&e.UpdatedAt)
		case "is_active":
			cm.Bool(&e.IsActive)
		case "city":
			cm.String(&e.City)
		case "company":
			cm.NullString(&e.Company)
		case "country_id":
			cm.String(&e.CountryID)
		case "fax":
			cm.NullString(&e.Fax)
		case "firstname":
			cm.String(&e.Firstname)
		case "lastname":
			cm.String(&e.Lastname)
		case "middlename":
			cm.NullString(&e.Middlename)
		case "postcode":
			cm.NullString(&e.Postcode)
		case "prefix":
			cm.NullString(&e.Prefix)
		case "region":
			cm.NullString(&e.Region)
		case "region_id":
			cm.NullUint32(&e.RegionID)
		case "street":
			cm.String(&e.Street)
		case "suffix":
			cm.NullString(&e.Suffix)
		case "telephone":
			cm.String(&e.Telephone)
		case "vat_id":
			cm.NullString(&e.VatID)
		case "vat_is_valid":
			cm.NullBool(&e.VatIsValid)
		case "vat_request_date":
			cm.NullString(&e.VatRequestDate)
		case "vat_request_id":
			cm.NullString(&e.VatRequestID)
		case "vat_request_success":
			cm.NullUint32(&e.VatRequestSuccess)
		default:
			return errors.NotFound.Newf("[dmltestgenerated] CustomerAddressEntity Column %q not found", c)
		}
	}
	return errors.WithStack(cm.Err())
}

func (e *CustomerAddressEntity) Load(ctx context.Context, dbm *DBM, entityID uint32, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerAddressEntitySelectByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return errors.NotValid.Newf("CustomerAddressEntity can't be nil")
	}
	// put the IDs entityID into the context as value to search for a cache entry in the event function.
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagBeforeSelect, nil, e); err != nil {
		return errors.WithStack(err)
	}
	if e.IsSet() {
		return nil // might return data from cache
	}
	if _, err = dbm.CachedQuery("CustomerAddressEntitySelectByPK").ApplyCallBacks(opts...).Load(ctx, e, entityID); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagAfterSelect, nil, e))
}

func (e *CustomerAddressEntity) Delete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerAddressEntityDeleteByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CustomerAddressEntity can't be nil")
	}
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagBeforeDelete, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CustomerAddressEntityDeleteByPK").ApplyCallBacks(opts...).ExecContext(ctx, e.EntityID); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagAfterDelete, nil, e)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CustomerAddressEntity) Update(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerAddressEntityUpdateByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CustomerAddressEntity can't be nil")
	}
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagBeforeUpdate, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CustomerAddressEntityUpdateByPK").ApplyCallBacks(opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagAfterUpdate, nil, e)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CustomerAddressEntity) Insert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerAddressEntityInsert")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CustomerAddressEntity can't be nil")
	}
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagBeforeInsert, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CustomerAddressEntityInsert").ApplyCallBacks(opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagAfterInsert, nil, e)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CustomerAddressEntity) Upsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerAddressEntityUpsertByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CustomerAddressEntity can't be nil")
	}
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagBeforeUpsert, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CustomerAddressEntityUpsertByPK").ApplyCallBacks(opts...).ExecContext(ctx, dml.Qualify("", e)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagAfterUpsert, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

// Empty empties all the fields of the current object. Also known as Reset.
func (e *CustomerAddressEntity) Empty() *CustomerAddressEntity {
	*e = CustomerAddressEntity{}
	return e
}

// IsSet returns true if the entity has non-empty primary keys.
func (e *CustomerAddressEntity) IsSet() bool { return e.EntityID > 0 }

// This variable can be set in another file to provide a custom validator.
var validateCustomerAddressEntity func(*CustomerAddressEntity) error

// Validate runs internal consistency tests.
func (e *CustomerAddressEntity) Validate() error {
	if e == nil {
		return errors.NotValid.Newf("Type %T cannot be nil", e)
	}
	if validateCustomerAddressEntity != nil {
		return validateCustomerAddressEntity(e)
	}
	return nil
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (e *CustomerAddressEntity) WriteTo(w io.Writer) (n int64, err error) {
	// for now this printing is good enough. If you need better swap out with your code.
	n2, err := fmt.Fprint(w,
		"entity_id:", e.EntityID, "\n",
		"increment_id:", e.IncrementID, "\n",
		"parent_id:", e.ParentID, "\n",
		"created_at:", e.CreatedAt, "\n",
		"updated_at:", e.UpdatedAt, "\n",
		"is_active:", e.IsActive, "\n",
		"city:", e.City, "\n",
		"company:", e.Company, "\n",
		"country_id:", e.CountryID, "\n",
		"fax:", e.Fax, "\n",
		"firstname:", e.Firstname, "\n",
		"lastname:", e.Lastname, "\n",
		"middlename:", e.Middlename, "\n",
		"postcode:", e.Postcode, "\n",
		"prefix:", e.Prefix, "\n",
		"region:", e.Region, "\n",
		"region_id:", e.RegionID, "\n",
		"street:", e.Street, "\n",
		"suffix:", e.Suffix, "\n",
		"telephone:", e.Telephone, "\n",
		"vat_id:", e.VatID, "\n",
		"vat_is_valid:", e.VatIsValid, "\n",
		"vat_request_date:", e.VatRequestDate, "\n",
		"vat_request_id:", e.VatRequestID, "\n",
		"vat_request_success:", e.VatRequestSuccess, "\n",
	)
	return int64(n2), err
}

// CustomerAddressEntities represents a collection type for DB table
// customer_address_entity
// Not thread safe. Auto generated.
//easyjson:json
type CustomerAddressEntities struct {
	Data []*CustomerAddressEntity `json:"data,omitempty"`
}

// NewCustomerAddressEntities  creates a new initialized collection. Auto
// generated.
func NewCustomerAddressEntities() *CustomerAddressEntities {
	return &CustomerAddressEntities{
		Data: make([]*CustomerAddressEntity, 0, 5),
	}
}

// Append will add a new item at the end of * CustomerAddressEntities . Auto
// generated via dmlgen.
func (cc *CustomerAddressEntities) Append(n ...*CustomerAddressEntity) *CustomerAddressEntities {
	cc.Data = append(cc.Data, n...)
	return cc
}

// UnmarshalBinary implements encoding.BinaryUnmarshaler.
func (cc *CustomerAddressEntities) UnmarshalBinary(data []byte) error {
	return cc.Unmarshal(data) // Implemented via github.com/gogo/protobuf
}

// MarshalBinary implements encoding.BinaryMarshaler.
func (cc *CustomerAddressEntities) MarshalBinary() (data []byte, err error) {
	return cc.Marshal() // Implemented via github.com/gogo/protobuf
}

// Cut will remove items i through j-1. Auto generated via dmlgen.
func (cc *CustomerAddressEntities) Cut(i, j int) *CustomerAddressEntities {
	z := cc.Data // copy slice header
	copy(z[i:], z[j:])
	for k, n := len(z)-j+i, len(z); k < n; k++ {
		z[k] = nil // this avoids the memory leak
	}
	z = z[:len(z)-j+i]
	cc.Data = z
	return cc
}

// AssignLastInsertID traverses through the slice and sets an incrementing new ID
// to each entity.
func (cc *CustomerAddressEntities) AssignLastInsertID(id int64) {
	for i := int64(0); i < int64(len(cc.Data)); i++ {
		cc.Data[i].AssignLastInsertID(id + i)
	}
}

func (cc *CustomerAddressEntities) scanColumns(cm *dml.ColumnMap, e *CustomerAddressEntity, idx uint64) error {
	if err := e.MapColumns(cm); err != nil {
		return errors.WithStack(err)
	}
	// this function might get extended.
	return nil
}

// MapColumns implements dml.ColumnMapper interface. Auto generated.
func (cc *CustomerAddressEntities) MapColumns(cm *dml.ColumnMap) error {
	switch m := cm.Mode(); m {
	case dml.ColumnMapEntityReadAll, dml.ColumnMapEntityReadSet:
		for i, e := range cc.Data {
			if err := cc.scanColumns(cm, e, uint64(i)); err != nil {
				return errors.WithStack(err)
			}
		}
	case dml.ColumnMapScan:
		if cm.Count == 0 {
			cc.Data = cc.Data[:0]
		}
		e := new(CustomerAddressEntity)
		if err := cc.scanColumns(cm, e, cm.Count); err != nil {
			return errors.WithStack(err)
		}
		cc.Data = append(cc.Data, e)
	case dml.ColumnMapCollectionReadSet:
		for cm.Next() {
			switch c := cm.Column(); c {
			case "entity_id":
				cm = cm.Uint32s(cc.EntityIDs()...)
			default:
				return errors.NotFound.Newf("[dmltestgenerated] CustomerAddressEntities Column %q not found", c)
			}
		} // end for cm.Next

	default:
		return errors.NotSupported.Newf("[dmltestgenerated] Unknown Mode: %q", string(m))
	}
	return cm.Err()
}

func (cc *CustomerAddressEntities) DBLoad(ctx context.Context, dbm *DBM, pkIDs []uint32, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerAddressEntitiesDBLoad")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("CustomerAddressEntity can't be nil")
	}
	// put the IDs EntityID into the context as value to search for a cache entry in the event function.
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagBeforeSelect, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	if cc.Data != nil {
		return nil // might return data from cache
	}
	if len(pkIDs) > 0 {
		if _, err = dbm.CachedQuery("CustomerAddressEntitiesSelectByPK").ApplyCallBacks(opts...).Load(ctx, cc, pkIDs); err != nil {
			return errors.WithStack(err)
		}
	} else {
		if _, err = dbm.CachedQuery("CustomerAddressEntitiesSelectAll").ApplyCallBacks(opts...).Load(ctx, cc); err != nil {
			return errors.WithStack(err)
		}
	}
	return errors.WithStack(dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagAfterSelect, cc, nil))
}

func (cc *CustomerAddressEntities) DBDelete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerAddressEntitiesDeleteByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("CustomerAddressEntities can't be nil")
	}
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagBeforeDelete, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CustomerAddressEntityDeleteByPK").ApplyCallBacks(opts...).ExecContext(ctx, dml.Qualify("", cc)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagAfterDelete, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *CustomerAddressEntities) DBUpdate(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerAddressEntitiesUpdateByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("CustomerAddressEntities can't be nil")
	}
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagBeforeUpdate, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CustomerAddressEntityUpdateByPK").ApplyCallBacks(opts...).ExecContext(ctx, cc); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagAfterUpdate, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *CustomerAddressEntities) DBInsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerAddressEntitiesInsert")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("CustomerAddressEntities can't be nil")
	}
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagBeforeInsert, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CustomerAddressEntityInsert").ApplyCallBacks(opts...).ExecContext(ctx, cc); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagAfterInsert, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *CustomerAddressEntities) DBUpsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerAddressEntitiesUpsertByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("CustomerAddressEntities can't be nil")
	}
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagBeforeUpsert, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CustomerAddressEntityUpsertByPK").ApplyCallBacks(opts...).ExecContext(ctx, dml.Qualify("", cc)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCustomerAddressEntityFunc(ctx, dml.EventFlagAfterUpsert, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

// Delete will remove an item from the slice. Auto generated via dmlgen.
func (cc *CustomerAddressEntities) Delete(i int) *CustomerAddressEntities {
	z := cc.Data // copy the slice header
	end := len(z) - 1
	cc.Swap(i, end)
	copy(z[i:], z[i+1:])
	z[end] = nil // this should avoid the memory leak
	z = z[:end]
	cc.Data = z
	return cc
}

// Each will run function f on all items in []* CustomerAddressEntity . Auto
// generated via dmlgen.
func (cc *CustomerAddressEntities) Each(f func(*CustomerAddressEntity)) *CustomerAddressEntities {
	if cc == nil {
		return nil
	}
	for i := range cc.Data {
		f(cc.Data[i])
	}
	return cc
}

// Filter filters the current slice by predicate f without memory allocation.
// Auto generated via dmlgen.
func (cc *CustomerAddressEntities) Filter(f func(*CustomerAddressEntity) bool) *CustomerAddressEntities {
	if cc == nil {
		return nil
	}
	b, i := cc.Data[:0], 0
	for _, e := range cc.Data {
		if f(e) {
			b = append(b, e)
		}
		i++
	}
	for i := len(b); i < len(cc.Data); i++ {
		cc.Data[i] = nil // this should avoid the memory leak
	}
	cc.Data = b
	return cc
}

// Insert will place a new item at position i. Auto generated via dmlgen.
func (cc *CustomerAddressEntities) Insert(n *CustomerAddressEntity, i int) *CustomerAddressEntities {
	z := cc.Data // copy the slice header
	z = append(z, &CustomerAddressEntity{})
	copy(z[i+1:], z[i:])
	z[i] = n
	cc.Data = z
	return cc
}

// Swap will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *CustomerAddressEntities) Swap(i, j int) { cc.Data[i], cc.Data[j] = cc.Data[j], cc.Data[i] }

// Len will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *CustomerAddressEntities) Len() int {
	if cc == nil {
		return 0
	}
	return len(cc.Data)
}

// EntityIDs returns a slice with the data or appends it to a slice.
// Auto generated.
func (cc *CustomerAddressEntities) EntityIDs(ret ...uint32) []uint32 {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]uint32, 0, len(cc.Data))
	}
	for _, e := range cc.Data {
		ret = append(ret, e.EntityID)
	}
	return ret
}

// Validate runs internal consistency tests on all items.
func (cc *CustomerAddressEntities) Validate() (err error) {
	if len(cc.Data) == 0 {
		return nil
	}
	for i, ld := 0, len(cc.Data); i < ld && err == nil; i++ {
		err = cc.Data[i].Validate()
	}
	return
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (cc *CustomerAddressEntities) WriteTo(w io.Writer) (n int64, err error) {
	for i, d := range cc.Data {
		n2, err := d.WriteTo(w)
		if err != nil {
			return 0, errors.Wrapf(err, "[dmltestgenerated] WriteTo failed at index %d", i)
		}
		n += n2
	}
	return n, nil
}

// CustomerEntity represents a single row for DB table customer_entity. Auto
// generated.
// Table comment: Customer Entity
//easyjson:json
type CustomerEntity struct {
	EntityID                uint32                   `max_len:"10"`  // entity_id int(10) unsigned NOT NULL PRI  auto_increment "Entity ID"
	WebsiteID               null.Uint32              `max_len:"5"`   // website_id smallint(5) unsigned NULL MUL DEFAULT 'NULL'  "Website ID"
	Email                   null.String              `max_len:"255"` // email varchar(255) NULL MUL DEFAULT 'NULL'  "Email"
	GroupID                 uint32                   `max_len:"5"`   // group_id smallint(5) unsigned NOT NULL  DEFAULT '0'  "Group ID"
	IncrementID             null.String              `max_len:"50"`  // increment_id varchar(50) NULL  DEFAULT 'NULL'  "Increment Id"
	StoreID                 null.Uint32              `max_len:"5"`   // store_id smallint(5) unsigned NULL MUL DEFAULT '0'  "Store ID"
	CreatedAt               time.Time                // created_at timestamp NOT NULL  DEFAULT 'current_timestamp()'  "Created At"
	UpdatedAt               time.Time                // updated_at timestamp NOT NULL  DEFAULT 'current_timestamp()' on update current_timestamp() "Updated At"
	IsActive                bool                     `max_len:"5"`   // is_active smallint(5) unsigned NOT NULL  DEFAULT '1'  "Is Active"
	DisableAutoGroupChange  uint32                   `max_len:"5"`   // disable_auto_group_change smallint(5) unsigned NOT NULL  DEFAULT '0'  "Disable automatic group change based on VAT ID"
	CreatedIn               null.String              `max_len:"255"` // created_in varchar(255) NULL  DEFAULT 'NULL'  "Created From"
	Prefix                  null.String              `max_len:"40"`  // prefix varchar(40) NULL  DEFAULT 'NULL'  "Name Prefix"
	Firstname               null.String              `max_len:"255"` // firstname varchar(255) NULL MUL DEFAULT 'NULL'  "First Name"
	Middlename              null.String              `max_len:"255"` // middlename varchar(255) NULL  DEFAULT 'NULL'  "Middle Name/Initial"
	Lastname                null.String              `max_len:"255"` // lastname varchar(255) NULL MUL DEFAULT 'NULL'  "Last Name"
	Suffix                  null.String              `max_len:"40"`  // suffix varchar(40) NULL  DEFAULT 'NULL'  "Name Suffix"
	Dob                     null.Time                // dob date NULL  DEFAULT 'NULL'  "Date of Birth"
	passwordHash            null.String              `max_len:"128"` // password_hash varchar(128) NULL  DEFAULT 'NULL'  "Password_hash"
	RpToken                 null.String              `max_len:"128"` // rp_token varchar(128) NULL  DEFAULT 'NULL'  "Reset password token"
	RpTokenCreatedAt        null.Time                // rp_token_created_at datetime NULL  DEFAULT 'NULL'  "Reset password token creation time"
	DefaultBilling          null.Uint32              `max_len:"10"` // default_billing int(10) unsigned NULL  DEFAULT 'NULL'  "Default Billing Address"
	DefaultShipping         null.Uint32              `max_len:"10"` // default_shipping int(10) unsigned NULL  DEFAULT 'NULL'  "Default Shipping Address"
	Taxvat                  null.String              `max_len:"50"` // taxvat varchar(50) NULL  DEFAULT 'NULL'  "Tax/VAT Number"
	Confirmation            null.String              `max_len:"64"` // confirmation varchar(64) NULL  DEFAULT 'NULL'  "Is Confirmed"
	Gender                  null.Uint32              `max_len:"5"`  // gender smallint(5) unsigned NULL  DEFAULT 'NULL'  "Gender"
	FailuresNum             null.Int32               `max_len:"5"`  // failures_num smallint(6) NULL  DEFAULT '0'  "Failure Number"
	FirstFailure            null.Time                // first_failure timestamp NULL  DEFAULT 'NULL'  "First Failure"
	LockExpires             null.Time                // lock_expires timestamp NULL  DEFAULT 'NULL'  "Lock Expiration Date"
	CustomerAddressEntities *CustomerAddressEntities // Reversed 1:M customer_entity.entity_id => customer_address_entity.parent_id
}

// Copy copies the struct and returns a new pointer. TODO use deepcopy tool to
// generate code afterwards
func (e *CustomerEntity) Copy() *CustomerEntity {
	e2 := new(CustomerEntity)
	*e2 = *e // for now a shallow copy
	return e2
}

// AssignLastInsertID updates the increment ID field with the last inserted ID
// from an INSERT operation. Implements dml.InsertIDAssigner. Auto generated.
func (e *CustomerEntity) AssignLastInsertID(id int64) {
	e.EntityID = uint32(id)
}

// MapColumns implements interface ColumnMapper only partially. Auto generated.
func (e *CustomerEntity) MapColumns(cm *dml.ColumnMap) error {
	if cm.Mode() == dml.ColumnMapEntityReadAll {
		return cm.Uint32(&e.EntityID).NullUint32(&e.WebsiteID).NullString(&e.Email).Uint32(&e.GroupID).NullString(&e.IncrementID).NullUint32(&e.StoreID).Time(&e.CreatedAt).Time(&e.UpdatedAt).Bool(&e.IsActive).Uint32(&e.DisableAutoGroupChange).NullString(&e.CreatedIn).NullString(&e.Prefix).NullString(&e.Firstname).NullString(&e.Middlename).NullString(&e.Lastname).NullString(&e.Suffix).NullTime(&e.Dob).NullString(&e.passwordHash).NullString(&e.RpToken).NullTime(&e.RpTokenCreatedAt).NullUint32(&e.DefaultBilling).NullUint32(&e.DefaultShipping).NullString(&e.Taxvat).NullString(&e.Confirmation).NullUint32(&e.Gender).NullInt32(&e.FailuresNum).NullTime(&e.FirstFailure).NullTime(&e.LockExpires).Err()
	}
	for cm.Next() {
		switch c := cm.Column(); c {
		case "entity_id":
			cm.Uint32(&e.EntityID)
		case "website_id":
			cm.NullUint32(&e.WebsiteID)
		case "email":
			cm.NullString(&e.Email)
		case "group_id":
			cm.Uint32(&e.GroupID)
		case "increment_id":
			cm.NullString(&e.IncrementID)
		case "store_id":
			cm.NullUint32(&e.StoreID)
		case "created_at":
			cm.Time(&e.CreatedAt)
		case "updated_at":
			cm.Time(&e.UpdatedAt)
		case "is_active":
			cm.Bool(&e.IsActive)
		case "disable_auto_group_change":
			cm.Uint32(&e.DisableAutoGroupChange)
		case "created_in":
			cm.NullString(&e.CreatedIn)
		case "prefix":
			cm.NullString(&e.Prefix)
		case "firstname":
			cm.NullString(&e.Firstname)
		case "middlename":
			cm.NullString(&e.Middlename)
		case "lastname":
			cm.NullString(&e.Lastname)
		case "suffix":
			cm.NullString(&e.Suffix)
		case "dob":
			cm.NullTime(&e.Dob)
		case "password_hash":
			cm.NullString(&e.passwordHash)
		case "rp_token":
			cm.NullString(&e.RpToken)
		case "rp_token_created_at":
			cm.NullTime(&e.RpTokenCreatedAt)
		case "default_billing":
			cm.NullUint32(&e.DefaultBilling)
		case "default_shipping":
			cm.NullUint32(&e.DefaultShipping)
		case "taxvat":
			cm.NullString(&e.Taxvat)
		case "confirmation":
			cm.NullString(&e.Confirmation)
		case "gender":
			cm.NullUint32(&e.Gender)
		case "failures_num":
			cm.NullInt32(&e.FailuresNum)
		case "first_failure":
			cm.NullTime(&e.FirstFailure)
		case "lock_expires":
			cm.NullTime(&e.LockExpires)
		default:
			return errors.NotFound.Newf("[dmltestgenerated] CustomerEntity Column %q not found", c)
		}
	}
	return errors.WithStack(cm.Err())
}

func (e *CustomerEntity) Load(ctx context.Context, dbm *DBM, entityID uint32, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerEntitySelectByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return errors.NotValid.Newf("CustomerEntity can't be nil")
	}
	// put the IDs entityID into the context as value to search for a cache entry in the event function.
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagBeforeSelect, nil, e); err != nil {
		return errors.WithStack(err)
	}
	if e.IsSet() {
		return nil // might return data from cache
	}
	if _, err = dbm.CachedQuery("CustomerEntitySelectByPK").ApplyCallBacks(opts...).Load(ctx, e, entityID); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventCustomerEntityFunc(ctx, dml.EventFlagAfterSelect, nil, e))
}

func (e *CustomerEntity) Delete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerEntityDeleteByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CustomerEntity can't be nil")
	}
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagBeforeDelete, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CustomerEntityDeleteByPK").ApplyCallBacks(opts...).ExecContext(ctx, e.EntityID); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCustomerEntityFunc(ctx, dml.EventFlagAfterDelete, nil, e)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CustomerEntity) Update(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerEntityUpdateByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CustomerEntity can't be nil")
	}
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagBeforeUpdate, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CustomerEntityUpdateByPK").ApplyCallBacks(opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCustomerEntityFunc(ctx, dml.EventFlagAfterUpdate, nil, e)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CustomerEntity) Insert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerEntityInsert")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CustomerEntity can't be nil")
	}
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagBeforeInsert, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CustomerEntityInsert").ApplyCallBacks(opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCustomerEntityFunc(ctx, dml.EventFlagAfterInsert, nil, e)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *CustomerEntity) Upsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerEntityUpsertByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("CustomerEntity can't be nil")
	}
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagBeforeUpsert, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CustomerEntityUpsertByPK").ApplyCallBacks(opts...).ExecContext(ctx, dml.Qualify("", e)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagAfterUpsert, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

// Empty empties all the fields of the current object. Also known as Reset.
func (e *CustomerEntity) Empty() *CustomerEntity { *e = CustomerEntity{}; return e }

// IsSet returns true if the entity has non-empty primary keys.
func (e *CustomerEntity) IsSet() bool { return e.EntityID > 0 }

// Set PasswordHash  sets the data for a private and security sensitive field.
func (e *CustomerEntity) SetPasswordHash(d null.String) *CustomerEntity {
	e.passwordHash = d
	return e
}

// Get PasswordHash  returns the data from a private and security sensitive
// field.
func (e *CustomerEntity) GetPasswordHash() null.String {
	return e.passwordHash
}

// This variable can be set in another file to provide a custom validator.
var validateCustomerEntity func(*CustomerEntity) error

// Validate runs internal consistency tests.
func (e *CustomerEntity) Validate() error {
	if e == nil {
		return errors.NotValid.Newf("Type %T cannot be nil", e)
	}
	if validateCustomerEntity != nil {
		return validateCustomerEntity(e)
	}
	return nil
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (e *CustomerEntity) WriteTo(w io.Writer) (n int64, err error) {
	// for now this printing is good enough. If you need better swap out with your code.
	n2, err := fmt.Fprint(w,
		"entity_id:", e.EntityID, "\n",
		"website_id:", e.WebsiteID, "\n",
		"email:", e.Email, "\n",
		"group_id:", e.GroupID, "\n",
		"increment_id:", e.IncrementID, "\n",
		"store_id:", e.StoreID, "\n",
		"created_at:", e.CreatedAt, "\n",
		"updated_at:", e.UpdatedAt, "\n",
		"is_active:", e.IsActive, "\n",
		"disable_auto_group_change:", e.DisableAutoGroupChange, "\n",
		"created_in:", e.CreatedIn, "\n",
		"prefix:", e.Prefix, "\n",
		"firstname:", e.Firstname, "\n",
		"middlename:", e.Middlename, "\n",
		"lastname:", e.Lastname, "\n",
		"suffix:", e.Suffix, "\n",
		"dob:", e.Dob, "\n",
		"rp_token:", e.RpToken, "\n",
		"rp_token_created_at:", e.RpTokenCreatedAt, "\n",
		"default_billing:", e.DefaultBilling, "\n",
		"default_shipping:", e.DefaultShipping, "\n",
		"taxvat:", e.Taxvat, "\n",
		"confirmation:", e.Confirmation, "\n",
		"gender:", e.Gender, "\n",
		"failures_num:", e.FailuresNum, "\n",
		"first_failure:", e.FirstFailure, "\n",
		"lock_expires:", e.LockExpires, "\n",
	)
	return int64(n2), err
}

// CustomerEntities represents a collection type for DB table customer_entity
// Not thread safe. Auto generated.
//easyjson:json
type CustomerEntities struct {
	Data []*CustomerEntity `json:"data,omitempty"`
}

// NewCustomerEntities  creates a new initialized collection. Auto generated.
func NewCustomerEntities() *CustomerEntities {
	return &CustomerEntities{
		Data: make([]*CustomerEntity, 0, 5),
	}
}

// Append will add a new item at the end of * CustomerEntities . Auto generated
// via dmlgen.
func (cc *CustomerEntities) Append(n ...*CustomerEntity) *CustomerEntities {
	cc.Data = append(cc.Data, n...)
	return cc
}

// UnmarshalBinary implements encoding.BinaryUnmarshaler.
func (cc *CustomerEntities) UnmarshalBinary(data []byte) error {
	return cc.Unmarshal(data) // Implemented via github.com/gogo/protobuf
}

// MarshalBinary implements encoding.BinaryMarshaler.
func (cc *CustomerEntities) MarshalBinary() (data []byte, err error) {
	return cc.Marshal() // Implemented via github.com/gogo/protobuf
}

// Cut will remove items i through j-1. Auto generated via dmlgen.
func (cc *CustomerEntities) Cut(i, j int) *CustomerEntities {
	z := cc.Data // copy slice header
	copy(z[i:], z[j:])
	for k, n := len(z)-j+i, len(z); k < n; k++ {
		z[k] = nil // this avoids the memory leak
	}
	z = z[:len(z)-j+i]
	cc.Data = z
	return cc
}

// AssignLastInsertID traverses through the slice and sets an incrementing new ID
// to each entity.
func (cc *CustomerEntities) AssignLastInsertID(id int64) {
	for i := int64(0); i < int64(len(cc.Data)); i++ {
		cc.Data[i].AssignLastInsertID(id + i)
	}
}

func (cc *CustomerEntities) scanColumns(cm *dml.ColumnMap, e *CustomerEntity, idx uint64) error {
	if err := e.MapColumns(cm); err != nil {
		return errors.WithStack(err)
	}
	// this function might get extended.
	return nil
}

// MapColumns implements dml.ColumnMapper interface. Auto generated.
func (cc *CustomerEntities) MapColumns(cm *dml.ColumnMap) error {
	switch m := cm.Mode(); m {
	case dml.ColumnMapEntityReadAll, dml.ColumnMapEntityReadSet:
		for i, e := range cc.Data {
			if err := cc.scanColumns(cm, e, uint64(i)); err != nil {
				return errors.WithStack(err)
			}
		}
	case dml.ColumnMapScan:
		if cm.Count == 0 {
			cc.Data = cc.Data[:0]
		}
		e := new(CustomerEntity)
		if err := cc.scanColumns(cm, e, cm.Count); err != nil {
			return errors.WithStack(err)
		}
		cc.Data = append(cc.Data, e)
	case dml.ColumnMapCollectionReadSet:
		for cm.Next() {
			switch c := cm.Column(); c {
			case "entity_id":
				cm = cm.Uint32s(cc.EntityIDs()...)
			default:
				return errors.NotFound.Newf("[dmltestgenerated] CustomerEntities Column %q not found", c)
			}
		} // end for cm.Next

	default:
		return errors.NotSupported.Newf("[dmltestgenerated] Unknown Mode: %q", string(m))
	}
	return cm.Err()
}

func (cc *CustomerEntities) DBLoad(ctx context.Context, dbm *DBM, pkIDs []uint32, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerEntitiesDBLoad")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("CustomerEntity can't be nil")
	}
	// put the IDs EntityID into the context as value to search for a cache entry in the event function.
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagBeforeSelect, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	if cc.Data != nil {
		return nil // might return data from cache
	}
	if len(pkIDs) > 0 {
		if _, err = dbm.CachedQuery("CustomerEntitiesSelectByPK").ApplyCallBacks(opts...).Load(ctx, cc, pkIDs); err != nil {
			return errors.WithStack(err)
		}
	} else {
		if _, err = dbm.CachedQuery("CustomerEntitiesSelectAll").ApplyCallBacks(opts...).Load(ctx, cc); err != nil {
			return errors.WithStack(err)
		}
	}
	return errors.WithStack(dbm.eventCustomerEntityFunc(ctx, dml.EventFlagAfterSelect, cc, nil))
}

func (cc *CustomerEntities) DBDelete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerEntitiesDeleteByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("CustomerEntities can't be nil")
	}
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagBeforeDelete, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CustomerEntityDeleteByPK").ApplyCallBacks(opts...).ExecContext(ctx, dml.Qualify("", cc)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCustomerEntityFunc(ctx, dml.EventFlagAfterDelete, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *CustomerEntities) DBUpdate(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerEntitiesUpdateByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("CustomerEntities can't be nil")
	}
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagBeforeUpdate, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CustomerEntityUpdateByPK").ApplyCallBacks(opts...).ExecContext(ctx, cc); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCustomerEntityFunc(ctx, dml.EventFlagAfterUpdate, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *CustomerEntities) DBInsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerEntitiesInsert")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("CustomerEntities can't be nil")
	}
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagBeforeInsert, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CustomerEntityInsert").ApplyCallBacks(opts...).ExecContext(ctx, cc); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventCustomerEntityFunc(ctx, dml.EventFlagAfterInsert, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *CustomerEntities) DBUpsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "CustomerEntitiesUpsertByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("CustomerEntities can't be nil")
	}
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagBeforeUpsert, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("CustomerEntityUpsertByPK").ApplyCallBacks(opts...).ExecContext(ctx, dml.Qualify("", cc)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventCustomerEntityFunc(ctx, dml.EventFlagAfterUpsert, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

// Delete will remove an item from the slice. Auto generated via dmlgen.
func (cc *CustomerEntities) Delete(i int) *CustomerEntities {
	z := cc.Data // copy the slice header
	end := len(z) - 1
	cc.Swap(i, end)
	copy(z[i:], z[i+1:])
	z[end] = nil // this should avoid the memory leak
	z = z[:end]
	cc.Data = z
	return cc
}

// Each will run function f on all items in []* CustomerEntity . Auto generated
// via dmlgen.
func (cc *CustomerEntities) Each(f func(*CustomerEntity)) *CustomerEntities {
	if cc == nil {
		return nil
	}
	for i := range cc.Data {
		f(cc.Data[i])
	}
	return cc
}

// Filter filters the current slice by predicate f without memory allocation.
// Auto generated via dmlgen.
func (cc *CustomerEntities) Filter(f func(*CustomerEntity) bool) *CustomerEntities {
	if cc == nil {
		return nil
	}
	b, i := cc.Data[:0], 0
	for _, e := range cc.Data {
		if f(e) {
			b = append(b, e)
		}
		i++
	}
	for i := len(b); i < len(cc.Data); i++ {
		cc.Data[i] = nil // this should avoid the memory leak
	}
	cc.Data = b
	return cc
}

// Insert will place a new item at position i. Auto generated via dmlgen.
func (cc *CustomerEntities) Insert(n *CustomerEntity, i int) *CustomerEntities {
	z := cc.Data // copy the slice header
	z = append(z, &CustomerEntity{})
	copy(z[i+1:], z[i:])
	z[i] = n
	cc.Data = z
	return cc
}

// Swap will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *CustomerEntities) Swap(i, j int) { cc.Data[i], cc.Data[j] = cc.Data[j], cc.Data[i] }

// Len will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *CustomerEntities) Len() int {
	if cc == nil {
		return 0
	}
	return len(cc.Data)
}

// EntityIDs returns a slice with the data or appends it to a slice.
// Auto generated.
func (cc *CustomerEntities) EntityIDs(ret ...uint32) []uint32 {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]uint32, 0, len(cc.Data))
	}
	for _, e := range cc.Data {
		ret = append(ret, e.EntityID)
	}
	return ret
}

// Validate runs internal consistency tests on all items.
func (cc *CustomerEntities) Validate() (err error) {
	if len(cc.Data) == 0 {
		return nil
	}
	for i, ld := 0, len(cc.Data); i < ld && err == nil; i++ {
		err = cc.Data[i].Validate()
	}
	return
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (cc *CustomerEntities) WriteTo(w io.Writer) (n int64, err error) {
	for i, d := range cc.Data {
		n2, err := d.WriteTo(w)
		if err != nil {
			return 0, errors.Wrapf(err, "[dmltestgenerated] WriteTo failed at index %d", i)
		}
		n += n2
	}
	return n, nil
}

// DmlgenTypes represents a single row for DB table dmlgen_types. Auto generated.
// // Just another comment.
//easyjson:json
type DmlgenTypes struct {
	ID             int32        `json:"id,omitempty"  max_len:"10"`                     // id int(11) NOT NULL PRI  auto_increment ""
	ColBigint1     null.Int64   `json:"col_bigint_1,omitempty"  max_len:"19"`           // col_bigint_1 bigint(20) NULL  DEFAULT 'NULL'  ""
	ColBigint2     int64        `json:"col_bigint_2,omitempty"  max_len:"19"`           // col_bigint_2 bigint(20) NOT NULL  DEFAULT '0'  ""
	ColBigint3     null.Uint64  `json:"col_bigint_3,omitempty"  max_len:"20"`           // col_bigint_3 bigint(20) unsigned NULL  DEFAULT 'NULL'  ""
	ColBigint4     uint64       `json:"col_bigint_4,omitempty"  max_len:"20"`           // col_bigint_4 bigint(20) unsigned NOT NULL  DEFAULT '0'  ""
	ColBlob        []byte       `json:"col_blob,omitempty"  max_len:"65535"`            // col_blob blob NULL  DEFAULT 'NULL'  ""
	ColDate1       null.Time    `json:"col_date_1,omitempty"  `                         // col_date_1 date NULL  DEFAULT 'NULL'  ""
	ColDate2       time.Time    `json:"col_date_2,omitempty"  `                         // col_date_2 date NOT NULL  DEFAULT ''0000-00-00''  ""
	ColDatetime1   null.Time    `json:"col_datetime_1,omitempty"  `                     // col_datetime_1 datetime NULL  DEFAULT 'NULL'  ""
	ColDatetime2   time.Time    `json:"col_datetime_2,omitempty"  `                     // col_datetime_2 datetime NOT NULL  DEFAULT ''0000-00-00 00:00:00''  ""
	ColDecimal101  null.Decimal `json:"col_decimal_10_1,omitempty"  max_len:"10"`       // col_decimal_10_1 decimal(10,1) unsigned NULL  DEFAULT 'NULL'  ""
	ColDecimal124  null.Decimal `json:"col_decimal_12_4,omitempty"  max_len:"12"`       // col_decimal_12_4 decimal(12,4) NULL  DEFAULT 'NULL'  ""
	PriceA124      null.Decimal `json:"price_a_12_4,omitempty"  max_len:"12"`           // price_a_12_4 decimal(12,4) NULL  DEFAULT 'NULL'  ""
	PriceB124      null.Decimal `json:"price_b_12_4,omitempty"  max_len:"12"`           // price_b_12_4 decimal(12,4) NOT NULL  DEFAULT '0.0000'  ""
	ColDecimal123  null.Decimal `json:"col_decimal_12_3,omitempty"  max_len:"12"`       // col_decimal_12_3 decimal(12,3) NOT NULL  DEFAULT '0.000'  ""
	ColDecimal206  null.Decimal `json:"col_decimal_20_6,omitempty"  max_len:"20"`       // col_decimal_20_6 decimal(20,6) NOT NULL  DEFAULT '0.000000'  ""
	ColDecimal2412 null.Decimal `json:"col_decimal_24_12,omitempty"  max_len:"24"`      // col_decimal_24_12 decimal(24,12) NOT NULL  DEFAULT '0.000000000000'  ""
	ColInt1        null.Int32   `json:"col_int_1,omitempty"  max_len:"10"`              // col_int_1 int(10) NULL  DEFAULT 'NULL'  ""
	ColInt2        int32        `json:"col_int_2,omitempty"  max_len:"10"`              // col_int_2 int(10) NOT NULL  DEFAULT '0'  ""
	ColInt3        null.Uint32  `json:"col_int_3,omitempty"  max_len:"10"`              // col_int_3 int(10) unsigned NULL  DEFAULT 'NULL'  ""
	ColInt4        uint32       `json:"col_int_4,omitempty"  max_len:"10"`              // col_int_4 int(10) unsigned NOT NULL  DEFAULT '0'  ""
	ColLongtext1   null.String  `json:"col_longtext_1,omitempty"  max_len:"4294967295"` // col_longtext_1 longtext NULL  DEFAULT 'NULL'  ""
	ColLongtext2   string       `json:"col_longtext_2,omitempty"  max_len:"4294967295"` // col_longtext_2 longtext NOT NULL  DEFAULT ''''  ""
	ColMediumblob  []byte       `json:"col_mediumblob,omitempty"  max_len:"16777215"`   // col_mediumblob mediumblob NULL  DEFAULT 'NULL'  ""
	ColMediumtext1 null.String  `json:"col_mediumtext_1,omitempty"  max_len:"16777215"` // col_mediumtext_1 mediumtext NULL  DEFAULT 'NULL'  ""
	ColMediumtext2 string       `json:"col_mediumtext_2,omitempty"  max_len:"16777215"` // col_mediumtext_2 mediumtext NOT NULL  DEFAULT ''''  ""
	ColSmallint1   null.Int32   `json:"col_smallint_1,omitempty"  max_len:"5"`          // col_smallint_1 smallint(5) NULL  DEFAULT 'NULL'  ""
	ColSmallint2   int32        `json:"col_smallint_2,omitempty"  max_len:"5"`          // col_smallint_2 smallint(5) NOT NULL  DEFAULT '0'  ""
	ColSmallint3   null.Uint32  `json:"col_smallint_3,omitempty"  max_len:"5"`          // col_smallint_3 smallint(5) unsigned NULL  DEFAULT 'NULL'  ""
	ColSmallint4   uint32       `json:"col_smallint_4,omitempty"  max_len:"5"`          // col_smallint_4 smallint(5) unsigned NOT NULL  DEFAULT '0'  ""
	HasSmallint5   bool         `json:"has_smallint_5,omitempty"  max_len:"5"`          // has_smallint_5 smallint(5) unsigned NOT NULL  DEFAULT '0'  ""
	IsSmallint5    null.Bool    `json:"is_smallint_5,omitempty"  max_len:"5"`           // is_smallint_5 smallint(5) NULL  DEFAULT 'NULL'  ""
	ColText        null.String  `json:"col_text,omitempty"  max_len:"65535"`            // col_text text NULL  DEFAULT 'NULL'  ""
	ColTimestamp1  time.Time    `json:"col_timestamp_1,omitempty"  `                    // col_timestamp_1 timestamp NOT NULL  DEFAULT 'current_timestamp()'  ""
	ColTimestamp2  null.Time    `json:"col_timestamp_2,omitempty"  `                    // col_timestamp_2 timestamp NULL  DEFAULT 'NULL'  ""
	ColTinyint1    int32        `json:"col_tinyint_1,omitempty"  max_len:"3"`           // col_tinyint_1 tinyint(1) NOT NULL  DEFAULT '0'  ""
	ColVarchar1    string       `json:"col_varchar_1,omitempty"  max_len:"1"`           // col_varchar_1 varchar(1) NOT NULL  DEFAULT ''0''  ""
	ColVarchar100  null.String  `json:"col_varchar_100,omitempty"  max_len:"100"`       // col_varchar_100 varchar(100) NULL  DEFAULT 'NULL'  ""
	ColVarchar16   string       `json:"col_varchar_16,omitempty"  max_len:"16"`         // col_varchar_16 varchar(16) NOT NULL  DEFAULT ''de_DE''  ""
	ColChar1       null.String  `json:"col_char_1,omitempty"  max_len:"21"`             // col_char_1 char(21) NULL  DEFAULT 'NULL'  ""
	ColChar2       string       `json:"col_char_2,omitempty"  max_len:"17"`             // col_char_2 char(17) NOT NULL  DEFAULT ''xchar''  ""
}

// Copy copies the struct and returns a new pointer. TODO use deepcopy tool to
// generate code afterwards
func (e *DmlgenTypes) Copy() *DmlgenTypes {
	e2 := new(DmlgenTypes)
	*e2 = *e // for now a shallow copy
	return e2
}

// AssignLastInsertID updates the increment ID field with the last inserted ID
// from an INSERT operation. Implements dml.InsertIDAssigner. Auto generated.
func (e *DmlgenTypes) AssignLastInsertID(id int64) {
	e.ID = int32(id)
}

// MapColumns implements interface ColumnMapper only partially. Auto generated.
func (e *DmlgenTypes) MapColumns(cm *dml.ColumnMap) error {
	if cm.Mode() == dml.ColumnMapEntityReadAll {
		return cm.Int32(&e.ID).NullInt64(&e.ColBigint1).Int64(&e.ColBigint2).NullUint64(&e.ColBigint3).Uint64(&e.ColBigint4).Byte(&e.ColBlob).NullTime(&e.ColDate1).Time(&e.ColDate2).NullTime(&e.ColDatetime1).Time(&e.ColDatetime2).Decimal(&e.ColDecimal101).Decimal(&e.ColDecimal124).Decimal(&e.PriceA124).Decimal(&e.PriceB124).Decimal(&e.ColDecimal123).Decimal(&e.ColDecimal206).Decimal(&e.ColDecimal2412).NullInt32(&e.ColInt1).Int32(&e.ColInt2).NullUint32(&e.ColInt3).Uint32(&e.ColInt4).NullString(&e.ColLongtext1).String(&e.ColLongtext2).Byte(&e.ColMediumblob).NullString(&e.ColMediumtext1).String(&e.ColMediumtext2).NullInt32(&e.ColSmallint1).Int32(&e.ColSmallint2).NullUint32(&e.ColSmallint3).Uint32(&e.ColSmallint4).Bool(&e.HasSmallint5).NullBool(&e.IsSmallint5).NullString(&e.ColText).Time(&e.ColTimestamp1).NullTime(&e.ColTimestamp2).Int32(&e.ColTinyint1).String(&e.ColVarchar1).NullString(&e.ColVarchar100).String(&e.ColVarchar16).NullString(&e.ColChar1).String(&e.ColChar2).Err()
	}
	for cm.Next() {
		switch c := cm.Column(); c {
		case "id":
			cm.Int32(&e.ID)
		case "col_bigint_1":
			cm.NullInt64(&e.ColBigint1)
		case "col_bigint_2":
			cm.Int64(&e.ColBigint2)
		case "col_bigint_3":
			cm.NullUint64(&e.ColBigint3)
		case "col_bigint_4":
			cm.Uint64(&e.ColBigint4)
		case "col_blob":
			cm.Byte(&e.ColBlob)
		case "col_date_1":
			cm.NullTime(&e.ColDate1)
		case "col_date_2":
			cm.Time(&e.ColDate2)
		case "col_datetime_1":
			cm.NullTime(&e.ColDatetime1)
		case "col_datetime_2":
			cm.Time(&e.ColDatetime2)
		case "col_decimal_10_1":
			cm.Decimal(&e.ColDecimal101)
		case "col_decimal_12_4":
			cm.Decimal(&e.ColDecimal124)
		case "price_a_12_4":
			cm.Decimal(&e.PriceA124)
		case "price_b_12_4":
			cm.Decimal(&e.PriceB124)
		case "col_decimal_12_3":
			cm.Decimal(&e.ColDecimal123)
		case "col_decimal_20_6":
			cm.Decimal(&e.ColDecimal206)
		case "col_decimal_24_12":
			cm.Decimal(&e.ColDecimal2412)
		case "col_int_1":
			cm.NullInt32(&e.ColInt1)
		case "col_int_2":
			cm.Int32(&e.ColInt2)
		case "col_int_3":
			cm.NullUint32(&e.ColInt3)
		case "col_int_4":
			cm.Uint32(&e.ColInt4)
		case "col_longtext_1":
			cm.NullString(&e.ColLongtext1)
		case "col_longtext_2":
			cm.String(&e.ColLongtext2)
		case "col_mediumblob":
			cm.Byte(&e.ColMediumblob)
		case "col_mediumtext_1":
			cm.NullString(&e.ColMediumtext1)
		case "col_mediumtext_2":
			cm.String(&e.ColMediumtext2)
		case "col_smallint_1":
			cm.NullInt32(&e.ColSmallint1)
		case "col_smallint_2":
			cm.Int32(&e.ColSmallint2)
		case "col_smallint_3":
			cm.NullUint32(&e.ColSmallint3)
		case "col_smallint_4":
			cm.Uint32(&e.ColSmallint4)
		case "has_smallint_5":
			cm.Bool(&e.HasSmallint5)
		case "is_smallint_5":
			cm.NullBool(&e.IsSmallint5)
		case "col_text":
			cm.NullString(&e.ColText)
		case "col_timestamp_1":
			cm.Time(&e.ColTimestamp1)
		case "col_timestamp_2":
			cm.NullTime(&e.ColTimestamp2)
		case "col_tinyint_1":
			cm.Int32(&e.ColTinyint1)
		case "col_varchar_1":
			cm.String(&e.ColVarchar1)
		case "col_varchar_100":
			cm.NullString(&e.ColVarchar100)
		case "col_varchar_16":
			cm.String(&e.ColVarchar16)
		case "col_char_1":
			cm.NullString(&e.ColChar1)
		case "col_char_2":
			cm.String(&e.ColChar2)
		default:
			return errors.NotFound.Newf("[dmltestgenerated] DmlgenTypes Column %q not found", c)
		}
	}
	return errors.WithStack(cm.Err())
}

func (e *DmlgenTypes) Load(ctx context.Context, dbm *DBM, iD int32, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "DmlgenTypesSelectByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return errors.NotValid.Newf("DmlgenTypes can't be nil")
	}
	// put the IDs iD into the context as value to search for a cache entry in the event function.
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagBeforeSelect, nil, e); err != nil {
		return errors.WithStack(err)
	}
	if e.IsSet() {
		return nil // might return data from cache
	}
	if _, err = dbm.CachedQuery("DmlgenTypesSelectByPK").ApplyCallBacks(opts...).Load(ctx, e, iD); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagAfterSelect, nil, e))
}

func (e *DmlgenTypes) Delete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "DmlgenTypesDeleteByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("DmlgenTypes can't be nil")
	}
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagBeforeDelete, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("DmlgenTypesDeleteByPK").ApplyCallBacks(opts...).ExecContext(ctx, e.ID); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagAfterDelete, nil, e)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *DmlgenTypes) Update(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "DmlgenTypesUpdateByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("DmlgenTypes can't be nil")
	}
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagBeforeUpdate, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("DmlgenTypesUpdateByPK").ApplyCallBacks(opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagAfterUpdate, nil, e)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *DmlgenTypes) Insert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "DmlgenTypesInsert")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("DmlgenTypes can't be nil")
	}
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagBeforeInsert, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("DmlgenTypesInsert").ApplyCallBacks(opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagAfterInsert, nil, e)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *DmlgenTypes) Upsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "DmlgenTypesUpsertByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("DmlgenTypes can't be nil")
	}
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagBeforeUpsert, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("DmlgenTypesUpsertByPK").ApplyCallBacks(opts...).ExecContext(ctx, dml.Qualify("", e)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagAfterUpsert, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

// Empty empties all the fields of the current object. Also known as Reset.
func (e *DmlgenTypes) Empty() *DmlgenTypes { *e = DmlgenTypes{}; return e }

// IsSet returns true if the entity has non-empty primary keys.
func (e *DmlgenTypes) IsSet() bool { return e.ID != 0 }

// This variable can be set in another file to provide a custom validator.
var validateDmlgenTypes func(*DmlgenTypes) error

// Validate runs internal consistency tests.
func (e *DmlgenTypes) Validate() error {
	if e == nil {
		return errors.NotValid.Newf("Type %T cannot be nil", e)
	}
	if validateDmlgenTypes != nil {
		return validateDmlgenTypes(e)
	}
	return nil
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (e *DmlgenTypes) WriteTo(w io.Writer) (n int64, err error) {
	// for now this printing is good enough. If you need better swap out with your code.
	n2, err := fmt.Fprint(w,
		"id:", e.ID, "\n",
		"col_bigint_1:", e.ColBigint1, "\n",
		"col_bigint_2:", e.ColBigint2, "\n",
		"col_bigint_3:", e.ColBigint3, "\n",
		"col_bigint_4:", e.ColBigint4, "\n",
		"col_blob:", e.ColBlob, "\n",
		"col_date_1:", e.ColDate1, "\n",
		"col_date_2:", e.ColDate2, "\n",
		"col_datetime_1:", e.ColDatetime1, "\n",
		"col_datetime_2:", e.ColDatetime2, "\n",
		"col_decimal_10_1:", e.ColDecimal101, "\n",
		"col_decimal_12_4:", e.ColDecimal124, "\n",
		"price_a_12_4:", e.PriceA124, "\n",
		"price_b_12_4:", e.PriceB124, "\n",
		"col_decimal_12_3:", e.ColDecimal123, "\n",
		"col_decimal_20_6:", e.ColDecimal206, "\n",
		"col_decimal_24_12:", e.ColDecimal2412, "\n",
		"col_int_1:", e.ColInt1, "\n",
		"col_int_2:", e.ColInt2, "\n",
		"col_int_3:", e.ColInt3, "\n",
		"col_int_4:", e.ColInt4, "\n",
		"col_longtext_1:", e.ColLongtext1, "\n",
		"col_longtext_2:", e.ColLongtext2, "\n",
		"col_mediumblob:", e.ColMediumblob, "\n",
		"col_mediumtext_1:", e.ColMediumtext1, "\n",
		"col_mediumtext_2:", e.ColMediumtext2, "\n",
		"col_smallint_1:", e.ColSmallint1, "\n",
		"col_smallint_2:", e.ColSmallint2, "\n",
		"col_smallint_3:", e.ColSmallint3, "\n",
		"col_smallint_4:", e.ColSmallint4, "\n",
		"has_smallint_5:", e.HasSmallint5, "\n",
		"is_smallint_5:", e.IsSmallint5, "\n",
		"col_text:", e.ColText, "\n",
		"col_timestamp_1:", e.ColTimestamp1, "\n",
		"col_timestamp_2:", e.ColTimestamp2, "\n",
		"col_tinyint_1:", e.ColTinyint1, "\n",
		"col_varchar_1:", e.ColVarchar1, "\n",
		"col_varchar_100:", e.ColVarchar100, "\n",
		"col_varchar_16:", e.ColVarchar16, "\n",
		"col_char_1:", e.ColChar1, "\n",
		"col_char_2:", e.ColChar2, "\n",
	)
	return int64(n2), err
}

// DmlgenTypesCollection represents a collection type for DB table dmlgen_types
// Not thread safe. Auto generated.
// // Just another comment.
//easyjson:json
type DmlgenTypesCollection struct {
	Data []*DmlgenTypes `json:"data,omitempty"`
}

// NewDmlgenTypesCollection  creates a new initialized collection. Auto
// generated.
func NewDmlgenTypesCollection() *DmlgenTypesCollection {
	return &DmlgenTypesCollection{
		Data: make([]*DmlgenTypes, 0, 5),
	}
}

// Append will add a new item at the end of * DmlgenTypesCollection . Auto
// generated via dmlgen.
func (cc *DmlgenTypesCollection) Append(n ...*DmlgenTypes) *DmlgenTypesCollection {
	cc.Data = append(cc.Data, n...)
	return cc
}

// UnmarshalBinary implements encoding.BinaryUnmarshaler.
func (cc *DmlgenTypesCollection) UnmarshalBinary(data []byte) error {
	return cc.Unmarshal(data) // Implemented via github.com/gogo/protobuf
}

// MarshalBinary implements encoding.BinaryMarshaler.
func (cc *DmlgenTypesCollection) MarshalBinary() (data []byte, err error) {
	return cc.Marshal() // Implemented via github.com/gogo/protobuf
}

// Cut will remove items i through j-1. Auto generated via dmlgen.
func (cc *DmlgenTypesCollection) Cut(i, j int) *DmlgenTypesCollection {
	z := cc.Data // copy slice header
	copy(z[i:], z[j:])
	for k, n := len(z)-j+i, len(z); k < n; k++ {
		z[k] = nil // this avoids the memory leak
	}
	z = z[:len(z)-j+i]
	cc.Data = z
	return cc
}

// AssignLastInsertID traverses through the slice and sets an incrementing new ID
// to each entity.
func (cc *DmlgenTypesCollection) AssignLastInsertID(id int64) {
	for i := int64(0); i < int64(len(cc.Data)); i++ {
		cc.Data[i].AssignLastInsertID(id + i)
	}
}

func (cc *DmlgenTypesCollection) scanColumns(cm *dml.ColumnMap, e *DmlgenTypes, idx uint64) error {
	if err := e.MapColumns(cm); err != nil {
		return errors.WithStack(err)
	}
	// this function might get extended.
	return nil
}

// MapColumns implements dml.ColumnMapper interface. Auto generated.
func (cc *DmlgenTypesCollection) MapColumns(cm *dml.ColumnMap) error {
	switch m := cm.Mode(); m {
	case dml.ColumnMapEntityReadAll, dml.ColumnMapEntityReadSet:
		for i, e := range cc.Data {
			if err := cc.scanColumns(cm, e, uint64(i)); err != nil {
				return errors.WithStack(err)
			}
		}
	case dml.ColumnMapScan:
		if cm.Count == 0 {
			cc.Data = cc.Data[:0]
		}
		e := new(DmlgenTypes)
		if err := cc.scanColumns(cm, e, cm.Count); err != nil {
			return errors.WithStack(err)
		}
		cc.Data = append(cc.Data, e)
	case dml.ColumnMapCollectionReadSet:
		for cm.Next() {
			switch c := cm.Column(); c {
			case "id":
				cm = cm.Int32s(cc.IDs()...)
			default:
				return errors.NotFound.Newf("[dmltestgenerated] DmlgenTypesCollection Column %q not found", c)
			}
		} // end for cm.Next

	default:
		return errors.NotSupported.Newf("[dmltestgenerated] Unknown Mode: %q", string(m))
	}
	return cm.Err()
}

func (cc *DmlgenTypesCollection) DBLoad(ctx context.Context, dbm *DBM, pkIDs []int32, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "DmlgenTypesCollectionDBLoad")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("DmlgenTypes can't be nil")
	}
	// put the IDs ID into the context as value to search for a cache entry in the event function.
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagBeforeSelect, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	if cc.Data != nil {
		return nil // might return data from cache
	}
	if len(pkIDs) > 0 {
		if _, err = dbm.CachedQuery("DmlgenTypesCollectionSelectByPK").ApplyCallBacks(opts...).Load(ctx, cc, pkIDs); err != nil {
			return errors.WithStack(err)
		}
	} else {
		if _, err = dbm.CachedQuery("DmlgenTypesCollectionSelectAll").ApplyCallBacks(opts...).Load(ctx, cc); err != nil {
			return errors.WithStack(err)
		}
	}
	return errors.WithStack(dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagAfterSelect, cc, nil))
}

func (cc *DmlgenTypesCollection) DBDelete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "DmlgenTypesCollectionDeleteByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("DmlgenTypesCollection can't be nil")
	}
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagBeforeDelete, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("DmlgenTypesDeleteByPK").ApplyCallBacks(opts...).ExecContext(ctx, dml.Qualify("", cc)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagAfterDelete, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *DmlgenTypesCollection) DBUpdate(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "DmlgenTypesCollectionUpdateByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("DmlgenTypesCollection can't be nil")
	}
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagBeforeUpdate, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("DmlgenTypesUpdateByPK").ApplyCallBacks(opts...).ExecContext(ctx, cc); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagAfterUpdate, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *DmlgenTypesCollection) DBInsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "DmlgenTypesCollectionInsert")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("DmlgenTypesCollection can't be nil")
	}
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagBeforeInsert, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("DmlgenTypesInsert").ApplyCallBacks(opts...).ExecContext(ctx, cc); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagAfterInsert, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *DmlgenTypesCollection) DBUpsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "DmlgenTypesCollectionUpsertByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("DmlgenTypesCollection can't be nil")
	}
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagBeforeUpsert, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("DmlgenTypesUpsertByPK").ApplyCallBacks(opts...).ExecContext(ctx, dml.Qualify("", cc)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventDmlgenTypesFunc(ctx, dml.EventFlagAfterUpsert, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

// Delete will remove an item from the slice. Auto generated via dmlgen.
func (cc *DmlgenTypesCollection) Delete(i int) *DmlgenTypesCollection {
	z := cc.Data // copy the slice header
	end := len(z) - 1
	cc.Swap(i, end)
	copy(z[i:], z[i+1:])
	z[end] = nil // this should avoid the memory leak
	z = z[:end]
	cc.Data = z
	return cc
}

// Each will run function f on all items in []* DmlgenTypes . Auto generated via
// dmlgen.
func (cc *DmlgenTypesCollection) Each(f func(*DmlgenTypes)) *DmlgenTypesCollection {
	if cc == nil {
		return nil
	}
	for i := range cc.Data {
		f(cc.Data[i])
	}
	return cc
}

// Filter filters the current slice by predicate f without memory allocation.
// Auto generated via dmlgen.
func (cc *DmlgenTypesCollection) Filter(f func(*DmlgenTypes) bool) *DmlgenTypesCollection {
	if cc == nil {
		return nil
	}
	b, i := cc.Data[:0], 0
	for _, e := range cc.Data {
		if f(e) {
			b = append(b, e)
		}
		i++
	}
	for i := len(b); i < len(cc.Data); i++ {
		cc.Data[i] = nil // this should avoid the memory leak
	}
	cc.Data = b
	return cc
}

// Insert will place a new item at position i. Auto generated via dmlgen.
func (cc *DmlgenTypesCollection) Insert(n *DmlgenTypes, i int) *DmlgenTypesCollection {
	z := cc.Data // copy the slice header
	z = append(z, &DmlgenTypes{})
	copy(z[i+1:], z[i:])
	z[i] = n
	cc.Data = z
	return cc
}

// Swap will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *DmlgenTypesCollection) Swap(i, j int) { cc.Data[i], cc.Data[j] = cc.Data[j], cc.Data[i] }

// Len will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *DmlgenTypesCollection) Len() int {
	if cc == nil {
		return 0
	}
	return len(cc.Data)
}

// IDs returns a slice with the data or appends it to a slice.
// Auto generated.
func (cc *DmlgenTypesCollection) IDs(ret ...int32) []int32 {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]int32, 0, len(cc.Data))
	}
	for _, e := range cc.Data {
		ret = append(ret, e.ID)
	}
	return ret
}

// ColDate2s belongs to the column "col_date_2" and returns a slice or appends to
// a slice only unique values of that column. The values will be filtered
// internally in a Go map. No DB query gets executed. Auto generated.
func (cc *DmlgenTypesCollection) UniqueColDate2s(ret ...time.Time) []time.Time {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]time.Time, 0, len(cc.Data))
	}
	dupCheck := make(map[time.Time]bool, len(cc.Data))
	for _, e := range cc.Data {
		if !dupCheck[e.ColDate2] {
			ret = append(ret, e.ColDate2)
			dupCheck[e.ColDate2] = true
		}
	}
	return ret
}

// PriceA124s belongs to the column "price_a_12_4" and returns a slice or appends
// to a slice only unique values of that column. The values will be filtered
// internally in a Go map. No DB query gets executed. Auto generated.
func (cc *DmlgenTypesCollection) UniquePriceA124s(ret ...null.Decimal) []null.Decimal {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]null.Decimal, 0, len(cc.Data))
	}
	dupCheck := make(map[null.Decimal]bool, len(cc.Data))
	for _, e := range cc.Data {
		if !dupCheck[e.PriceA124] {
			ret = append(ret, e.PriceA124)
			dupCheck[e.PriceA124] = true
		}
	}
	return ret
}

// ColInt1s belongs to the column "col_int_1" and returns a slice or appends to a
// slice only unique values of that column. The values will be filtered
// internally in a Go map. No DB query gets executed. Auto generated.
func (cc *DmlgenTypesCollection) UniqueColInt1s(ret ...int32) []int32 {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]int32, 0, len(cc.Data))
	}
	dupCheck := make(map[int32]bool, len(cc.Data))
	for _, e := range cc.Data {
		if !dupCheck[e.ColInt1.Int32] {
			ret = append(ret, e.ColInt1.Int32)
			dupCheck[e.ColInt1.Int32] = true
		}
	}
	return ret
}

// ColInt2s belongs to the column "col_int_2" and returns a slice or appends to a
// slice only unique values of that column. The values will be filtered
// internally in a Go map. No DB query gets executed. Auto generated.
func (cc *DmlgenTypesCollection) UniqueColInt2s(ret ...int32) []int32 {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]int32, 0, len(cc.Data))
	}
	dupCheck := make(map[int32]bool, len(cc.Data))
	for _, e := range cc.Data {
		if !dupCheck[e.ColInt2] {
			ret = append(ret, e.ColInt2)
			dupCheck[e.ColInt2] = true
		}
	}
	return ret
}

// HasSmallint5s belongs to the column "has_smallint_5" and returns a slice or
// appends to a slice only unique values of that column. The values will be
// filtered internally in a Go map. No DB query gets executed. Auto generated.
func (cc *DmlgenTypesCollection) UniqueHasSmallint5s(ret ...bool) []bool {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]bool, 0, len(cc.Data))
	}
	dupCheck := make(map[bool]bool, len(cc.Data))
	for _, e := range cc.Data {
		if !dupCheck[e.HasSmallint5] {
			ret = append(ret, e.HasSmallint5)
			dupCheck[e.HasSmallint5] = true
		}
	}
	return ret
}

// ColVarchar100s belongs to the column "col_varchar_100" and returns a slice or
// appends to a slice only unique values of that column. The values will be
// filtered internally in a Go map. No DB query gets executed. Auto generated.
func (cc *DmlgenTypesCollection) UniqueColVarchar100s(ret ...string) []string {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]string, 0, len(cc.Data))
	}
	dupCheck := make(map[string]bool, len(cc.Data))
	for _, e := range cc.Data {
		if !dupCheck[e.ColVarchar100.Data] {
			ret = append(ret, e.ColVarchar100.Data)
			dupCheck[e.ColVarchar100.Data] = true
		}
	}
	return ret
}

// Validate runs internal consistency tests on all items.
func (cc *DmlgenTypesCollection) Validate() (err error) {
	if len(cc.Data) == 0 {
		return nil
	}
	for i, ld := 0, len(cc.Data); i < ld && err == nil; i++ {
		err = cc.Data[i].Validate()
	}
	return
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (cc *DmlgenTypesCollection) WriteTo(w io.Writer) (n int64, err error) {
	for i, d := range cc.Data {
		n2, err := d.WriteTo(w)
		if err != nil {
			return 0, errors.Wrapf(err, "[dmltestgenerated] WriteTo failed at index %d", i)
		}
		n += n2
	}
	return n, nil
}

// SalesOrderStatusState represents a single row for DB table
// sales_order_status_state. Auto generated.
// Table comment: Sales Order Status Table
//easyjson:json
type SalesOrderStatusState struct {
	Status         string `max_len:"32"` // status varchar(32) NOT NULL PRI   "Status"
	State          string `max_len:"32"` // state varchar(32) NOT NULL PRI   "Label"
	IsDefault      bool   `max_len:"5"`  // is_default smallint(5) unsigned NOT NULL  DEFAULT '0'  "Is Default"
	VisibleOnFront uint32 `max_len:"5"`  // visible_on_front smallint(5) unsigned NOT NULL  DEFAULT '0'  "Visible on front"
}

// Copy copies the struct and returns a new pointer. TODO use deepcopy tool to
// generate code afterwards
func (e *SalesOrderStatusState) Copy() *SalesOrderStatusState {
	e2 := new(SalesOrderStatusState)
	*e2 = *e // for now a shallow copy
	return e2
}

// MapColumns implements interface ColumnMapper only partially. Auto generated.
func (e *SalesOrderStatusState) MapColumns(cm *dml.ColumnMap) error {
	if cm.Mode() == dml.ColumnMapEntityReadAll {
		return cm.String(&e.Status).String(&e.State).Bool(&e.IsDefault).Uint32(&e.VisibleOnFront).Err()
	}
	for cm.Next() {
		switch c := cm.Column(); c {
		case "status":
			cm.String(&e.Status)
		case "state":
			cm.String(&e.State)
		case "is_default":
			cm.Bool(&e.IsDefault)
		case "visible_on_front":
			cm.Uint32(&e.VisibleOnFront)
		default:
			return errors.NotFound.Newf("[dmltestgenerated] SalesOrderStatusState Column %q not found", c)
		}
	}
	return errors.WithStack(cm.Err())
}

func (e *SalesOrderStatusState) Load(ctx context.Context, dbm *DBM, status string, state string, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "SalesOrderStatusStateSelectByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return errors.NotValid.Newf("SalesOrderStatusState can't be nil")
	}
	// put the IDs status,state into the context as value to search for a cache entry in the event function.
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagBeforeSelect, nil, e); err != nil {
		return errors.WithStack(err)
	}
	if e.IsSet() {
		return nil // might return data from cache
	}
	if _, err = dbm.CachedQuery("SalesOrderStatusStateSelectByPK").ApplyCallBacks(opts...).Load(ctx, e, status, state); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagAfterSelect, nil, e))
}

func (e *SalesOrderStatusState) Delete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "SalesOrderStatusStateDeleteByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("SalesOrderStatusState can't be nil")
	}
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagBeforeDelete, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("SalesOrderStatusStateDeleteByPK").ApplyCallBacks(opts...).ExecContext(ctx, e.Status, e.State); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagAfterDelete, nil, e)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *SalesOrderStatusState) Update(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "SalesOrderStatusStateUpdateByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("SalesOrderStatusState can't be nil")
	}
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagBeforeUpdate, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("SalesOrderStatusStateUpdateByPK").ApplyCallBacks(opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagAfterUpdate, nil, e)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *SalesOrderStatusState) Insert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "SalesOrderStatusStateInsert")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("SalesOrderStatusState can't be nil")
	}
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagBeforeInsert, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("SalesOrderStatusStateInsert").ApplyCallBacks(opts...).ExecContext(ctx, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagAfterInsert, nil, e)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (e *SalesOrderStatusState) Upsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "SalesOrderStatusStateUpsertByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return nil, errors.NotValid.Newf("SalesOrderStatusState can't be nil")
	}
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagBeforeUpsert, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("SalesOrderStatusStateUpsertByPK").ApplyCallBacks(opts...).ExecContext(ctx, dml.Qualify("", e)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagAfterUpsert, nil, e); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

// Empty empties all the fields of the current object. Also known as Reset.
func (e *SalesOrderStatusState) Empty() *SalesOrderStatusState {
	*e = SalesOrderStatusState{}
	return e
}

// IsSet returns true if the entity has non-empty primary keys.
func (e *SalesOrderStatusState) IsSet() bool { return e.Status != "" && e.State != "" }

// This variable can be set in another file to provide a custom validator.
var validateSalesOrderStatusState func(*SalesOrderStatusState) error

// Validate runs internal consistency tests.
func (e *SalesOrderStatusState) Validate() error {
	if e == nil {
		return errors.NotValid.Newf("Type %T cannot be nil", e)
	}
	if validateSalesOrderStatusState != nil {
		return validateSalesOrderStatusState(e)
	}
	return nil
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (e *SalesOrderStatusState) WriteTo(w io.Writer) (n int64, err error) {
	// for now this printing is good enough. If you need better swap out with your code.
	n2, err := fmt.Fprint(w,
		"status:", e.Status, "\n",
		"state:", e.State, "\n",
		"is_default:", e.IsDefault, "\n",
		"visible_on_front:", e.VisibleOnFront, "\n",
	)
	return int64(n2), err
}

// SalesOrderStatusStates represents a collection type for DB table
// sales_order_status_state
// Not thread safe. Auto generated.
//easyjson:json
type SalesOrderStatusStates struct {
	Data []*SalesOrderStatusState `json:"data,omitempty"`
}

// NewSalesOrderStatusStates  creates a new initialized collection. Auto
// generated.
func NewSalesOrderStatusStates() *SalesOrderStatusStates {
	return &SalesOrderStatusStates{
		Data: make([]*SalesOrderStatusState, 0, 5),
	}
}

// Append will add a new item at the end of * SalesOrderStatusStates . Auto
// generated via dmlgen.
func (cc *SalesOrderStatusStates) Append(n ...*SalesOrderStatusState) *SalesOrderStatusStates {
	cc.Data = append(cc.Data, n...)
	return cc
}

// UnmarshalBinary implements encoding.BinaryUnmarshaler.
func (cc *SalesOrderStatusStates) UnmarshalBinary(data []byte) error {
	return cc.Unmarshal(data) // Implemented via github.com/gogo/protobuf
}

// MarshalBinary implements encoding.BinaryMarshaler.
func (cc *SalesOrderStatusStates) MarshalBinary() (data []byte, err error) {
	return cc.Marshal() // Implemented via github.com/gogo/protobuf
}

// Cut will remove items i through j-1. Auto generated via dmlgen.
func (cc *SalesOrderStatusStates) Cut(i, j int) *SalesOrderStatusStates {
	z := cc.Data // copy slice header
	copy(z[i:], z[j:])
	for k, n := len(z)-j+i, len(z); k < n; k++ {
		z[k] = nil // this avoids the memory leak
	}
	z = z[:len(z)-j+i]
	cc.Data = z
	return cc
}

func (cc *SalesOrderStatusStates) scanColumns(cm *dml.ColumnMap, e *SalesOrderStatusState, idx uint64) error {
	if err := e.MapColumns(cm); err != nil {
		return errors.WithStack(err)
	}
	// this function might get extended.
	return nil
}

// MapColumns implements dml.ColumnMapper interface. Auto generated.
func (cc *SalesOrderStatusStates) MapColumns(cm *dml.ColumnMap) error {
	switch m := cm.Mode(); m {
	case dml.ColumnMapEntityReadAll, dml.ColumnMapEntityReadSet:
		for i, e := range cc.Data {
			if err := cc.scanColumns(cm, e, uint64(i)); err != nil {
				return errors.WithStack(err)
			}
		}
	case dml.ColumnMapScan:
		if cm.Count == 0 {
			cc.Data = cc.Data[:0]
		}
		e := new(SalesOrderStatusState)
		if err := cc.scanColumns(cm, e, cm.Count); err != nil {
			return errors.WithStack(err)
		}
		cc.Data = append(cc.Data, e)
	case dml.ColumnMapCollectionReadSet:
		for cm.Next() {
			switch c := cm.Column(); c {
			case "status":
				cm = cm.Strings(cc.Statuss()...)
			case "state":
				cm = cm.Strings(cc.States()...)
			default:
				return errors.NotFound.Newf("[dmltestgenerated] SalesOrderStatusStates Column %q not found", c)
			}
		} // end for cm.Next

	default:
		return errors.NotSupported.Newf("[dmltestgenerated] Unknown Mode: %q", string(m))
	}
	return cm.Err()
}

type SalesOrderStatusStatesDBLoadArgs struct {
	Status string
	State  string
}

func (cc *SalesOrderStatusStates) DBLoad(ctx context.Context, dbm *DBM, pkIDs []SalesOrderStatusStatesDBLoadArgs, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "SalesOrderStatusStatesDBLoad")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("SalesOrderStatusState can't be nil")
	}
	// put the IDs Status,State into the context as value to search for a cache entry in the event function.
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagBeforeSelect, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	if cc.Data != nil {
		return nil // might return data from cache
	}
	cacheKey := "SalesOrderStatusStatesSelectAll"
	var args []interface{}
	if len(pkIDs) > 0 {
		args = make([]interface{}, 0, len(pkIDs)*2)
		for _, pk := range pkIDs {
			args = append(args, pk.Status)
			args = append(args, pk.State)
		}
		cacheKey = "SalesOrderStatusStatesSelectByPK"
	}
	if _, err = dbm.CachedQuery(cacheKey).ApplyCallBacks(opts...).Load(ctx, cc, args...); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagAfterSelect, cc, nil))
}

func (cc *SalesOrderStatusStates) DBDelete(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "SalesOrderStatusStatesDeleteByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("SalesOrderStatusStates can't be nil")
	}
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagBeforeDelete, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("SalesOrderStatusStateDeleteByPK").ApplyCallBacks(opts...).ExecContext(ctx, dml.Qualify("", cc)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagAfterDelete, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *SalesOrderStatusStates) DBUpdate(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "SalesOrderStatusStatesUpdateByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("SalesOrderStatusStates can't be nil")
	}
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagBeforeUpdate, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("SalesOrderStatusStateUpdateByPK").ApplyCallBacks(opts...).ExecContext(ctx, cc); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagAfterUpdate, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *SalesOrderStatusStates) DBInsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "SalesOrderStatusStatesInsert")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("SalesOrderStatusStates can't be nil")
	}
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagBeforeInsert, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("SalesOrderStatusStateInsert").ApplyCallBacks(opts...).ExecContext(ctx, cc); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = errors.WithStack(dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagAfterInsert, cc, nil)); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

func (cc *SalesOrderStatusStates) DBUpsert(ctx context.Context, dbm *DBM, opts ...dml.DBRFunc) (res sql.Result, err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "SalesOrderStatusStatesUpsertByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return nil, errors.NotValid.Newf("SalesOrderStatusStates can't be nil")
	}
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagBeforeUpsert, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	if res, err = dbm.CachedQuery("SalesOrderStatusStateUpsertByPK").ApplyCallBacks(opts...).ExecContext(ctx, dml.Qualify("", cc)); err != nil {
		return nil, errors.WithStack(err)
	}
	if err = dbm.eventSalesOrderStatusStateFunc(ctx, dml.EventFlagAfterUpsert, cc, nil); err != nil {
		return nil, errors.WithStack(err)
	}
	return res, nil
}

// Delete will remove an item from the slice. Auto generated via dmlgen.
func (cc *SalesOrderStatusStates) Delete(i int) *SalesOrderStatusStates {
	z := cc.Data // copy the slice header
	end := len(z) - 1
	cc.Swap(i, end)
	copy(z[i:], z[i+1:])
	z[end] = nil // this should avoid the memory leak
	z = z[:end]
	cc.Data = z
	return cc
}

// Each will run function f on all items in []* SalesOrderStatusState . Auto
// generated via dmlgen.
func (cc *SalesOrderStatusStates) Each(f func(*SalesOrderStatusState)) *SalesOrderStatusStates {
	if cc == nil {
		return nil
	}
	for i := range cc.Data {
		f(cc.Data[i])
	}
	return cc
}

// Filter filters the current slice by predicate f without memory allocation.
// Auto generated via dmlgen.
func (cc *SalesOrderStatusStates) Filter(f func(*SalesOrderStatusState) bool) *SalesOrderStatusStates {
	if cc == nil {
		return nil
	}
	b, i := cc.Data[:0], 0
	for _, e := range cc.Data {
		if f(e) {
			b = append(b, e)
		}
		i++
	}
	for i := len(b); i < len(cc.Data); i++ {
		cc.Data[i] = nil // this should avoid the memory leak
	}
	cc.Data = b
	return cc
}

// Insert will place a new item at position i. Auto generated via dmlgen.
func (cc *SalesOrderStatusStates) Insert(n *SalesOrderStatusState, i int) *SalesOrderStatusStates {
	z := cc.Data // copy the slice header
	z = append(z, &SalesOrderStatusState{})
	copy(z[i+1:], z[i:])
	z[i] = n
	cc.Data = z
	return cc
}

// Swap will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *SalesOrderStatusStates) Swap(i, j int) { cc.Data[i], cc.Data[j] = cc.Data[j], cc.Data[i] }

// Len will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *SalesOrderStatusStates) Len() int {
	if cc == nil {
		return 0
	}
	return len(cc.Data)
}

// Statuss returns a slice with the data or appends it to a slice.
// Auto generated.
func (cc *SalesOrderStatusStates) Statuss(ret ...string) []string {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]string, 0, len(cc.Data))
	}
	for _, e := range cc.Data {
		ret = append(ret, e.Status)
	}
	return ret
}

// States returns a slice with the data or appends it to a slice.
// Auto generated.
func (cc *SalesOrderStatusStates) States(ret ...string) []string {
	if cc == nil {
		return nil
	}
	if ret == nil {
		ret = make([]string, 0, len(cc.Data))
	}
	for _, e := range cc.Data {
		ret = append(ret, e.State)
	}
	return ret
}

// Validate runs internal consistency tests on all items.
func (cc *SalesOrderStatusStates) Validate() (err error) {
	if len(cc.Data) == 0 {
		return nil
	}
	for i, ld := 0, len(cc.Data); i < ld && err == nil; i++ {
		err = cc.Data[i].Validate()
	}
	return
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (cc *SalesOrderStatusStates) WriteTo(w io.Writer) (n int64, err error) {
	for i, d := range cc.Data {
		n2, err := d.WriteTo(w)
		if err != nil {
			return 0, errors.Wrapf(err, "[dmltestgenerated] WriteTo failed at index %d", i)
		}
		n += n2
	}
	return n, nil
}

// ViewCustomerAutoIncrement represents a single row for DB table
// view_customer_auto_increment. Auto generated.
// Table comment: VIEW
//easyjson:json
type ViewCustomerAutoIncrement struct {
	CeEntityID uint32      `max_len:"10"`  // ce_entity_id int(10) unsigned NOT NULL  DEFAULT '0'  "Entity ID"
	Email      null.String `max_len:"255"` // email varchar(255) NULL  DEFAULT 'NULL'  "Email"
	Firstname  string      `max_len:"255"` // firstname varchar(255) NOT NULL    "First Name"
	Lastname   string      `max_len:"255"` // lastname varchar(255) NOT NULL    "Last Name"
	City       string      `max_len:"255"` // city varchar(255) NOT NULL    "City"
}

// Copy copies the struct and returns a new pointer. TODO use deepcopy tool to
// generate code afterwards
func (e *ViewCustomerAutoIncrement) Copy() *ViewCustomerAutoIncrement {
	e2 := new(ViewCustomerAutoIncrement)
	*e2 = *e // for now a shallow copy
	return e2
}

// MapColumns implements interface ColumnMapper only partially. Auto generated.
func (e *ViewCustomerAutoIncrement) MapColumns(cm *dml.ColumnMap) error {
	if cm.Mode() == dml.ColumnMapEntityReadAll {
		return cm.Uint32(&e.CeEntityID).NullString(&e.Email).String(&e.Firstname).String(&e.Lastname).String(&e.City).Err()
	}
	for cm.Next() {
		switch c := cm.Column(); c {
		case "ce_entity_id":
			cm.Uint32(&e.CeEntityID)
		case "email":
			cm.NullString(&e.Email)
		case "firstname":
			cm.String(&e.Firstname)
		case "lastname":
			cm.String(&e.Lastname)
		case "city":
			cm.String(&e.City)
		default:
			return errors.NotFound.Newf("[dmltestgenerated] ViewCustomerAutoIncrement Column %q not found", c)
		}
	}
	return errors.WithStack(cm.Err())
}

func (e *ViewCustomerAutoIncrement) Load(ctx context.Context, dbm *DBM, ceEntityID uint32, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "ViewCustomerAutoIncrementSelectByPK")
	defer func() { cstrace.Status(span, err); span.End() }()
	if e == nil {
		return errors.NotValid.Newf("ViewCustomerAutoIncrement can't be nil")
	}
	// put the IDs ceEntityID into the context as value to search for a cache entry in the event function.
	if err = dbm.eventViewCustomerAutoIncrementFunc(ctx, dml.EventFlagBeforeSelect, nil, e); err != nil {
		return errors.WithStack(err)
	}
	if e.IsSet() {
		return nil // might return data from cache
	}
	if _, err = dbm.CachedQuery("ViewCustomerAutoIncrementSelectByPK").ApplyCallBacks(opts...).Load(ctx, e, ceEntityID); err != nil {
		return errors.WithStack(err)
	}
	return errors.WithStack(dbm.eventViewCustomerAutoIncrementFunc(ctx, dml.EventFlagAfterSelect, nil, e))
}

// Empty empties all the fields of the current object. Also known as Reset.
func (e *ViewCustomerAutoIncrement) Empty() *ViewCustomerAutoIncrement {
	*e = ViewCustomerAutoIncrement{}
	return e
}

// IsSet returns true if the entity has non-empty primary keys.
func (e *ViewCustomerAutoIncrement) IsSet() bool { return e.CeEntityID > 0 }

// This variable can be set in another file to provide a custom validator.
var validateViewCustomerAutoIncrement func(*ViewCustomerAutoIncrement) error

// Validate runs internal consistency tests.
func (e *ViewCustomerAutoIncrement) Validate() error {
	if e == nil {
		return errors.NotValid.Newf("Type %T cannot be nil", e)
	}
	if validateViewCustomerAutoIncrement != nil {
		return validateViewCustomerAutoIncrement(e)
	}
	return nil
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (e *ViewCustomerAutoIncrement) WriteTo(w io.Writer) (n int64, err error) {
	// for now this printing is good enough. If you need better swap out with your code.
	n2, err := fmt.Fprint(w,
		"ce_entity_id:", e.CeEntityID, "\n",
		"email:", e.Email, "\n",
		"firstname:", e.Firstname, "\n",
		"lastname:", e.Lastname, "\n",
		"city:", e.City, "\n",
	)
	return int64(n2), err
}

// ViewCustomerAutoIncrements represents a collection type for DB table
// view_customer_auto_increment
// Not thread safe. Auto generated.
//easyjson:json
type ViewCustomerAutoIncrements struct {
	Data []*ViewCustomerAutoIncrement `json:"data,omitempty"`
}

// NewViewCustomerAutoIncrements  creates a new initialized collection. Auto
// generated.
func NewViewCustomerAutoIncrements() *ViewCustomerAutoIncrements {
	return &ViewCustomerAutoIncrements{
		Data: make([]*ViewCustomerAutoIncrement, 0, 5),
	}
}

// Append will add a new item at the end of * ViewCustomerAutoIncrements . Auto
// generated via dmlgen.
func (cc *ViewCustomerAutoIncrements) Append(n ...*ViewCustomerAutoIncrement) *ViewCustomerAutoIncrements {
	cc.Data = append(cc.Data, n...)
	return cc
}

// UnmarshalBinary implements encoding.BinaryUnmarshaler.
func (cc *ViewCustomerAutoIncrements) UnmarshalBinary(data []byte) error {
	return cc.Unmarshal(data) // Implemented via github.com/gogo/protobuf
}

// MarshalBinary implements encoding.BinaryMarshaler.
func (cc *ViewCustomerAutoIncrements) MarshalBinary() (data []byte, err error) {
	return cc.Marshal() // Implemented via github.com/gogo/protobuf
}

// Cut will remove items i through j-1. Auto generated via dmlgen.
func (cc *ViewCustomerAutoIncrements) Cut(i, j int) *ViewCustomerAutoIncrements {
	z := cc.Data // copy slice header
	copy(z[i:], z[j:])
	for k, n := len(z)-j+i, len(z); k < n; k++ {
		z[k] = nil // this avoids the memory leak
	}
	z = z[:len(z)-j+i]
	cc.Data = z
	return cc
}

func (cc *ViewCustomerAutoIncrements) scanColumns(cm *dml.ColumnMap, e *ViewCustomerAutoIncrement, idx uint64) error {
	if err := e.MapColumns(cm); err != nil {
		return errors.WithStack(err)
	}
	// this function might get extended.
	return nil
}

// MapColumns implements dml.ColumnMapper interface. Auto generated.
func (cc *ViewCustomerAutoIncrements) MapColumns(cm *dml.ColumnMap) error {
	switch m := cm.Mode(); m {
	case dml.ColumnMapEntityReadAll, dml.ColumnMapEntityReadSet:
		for i, e := range cc.Data {
			if err := cc.scanColumns(cm, e, uint64(i)); err != nil {
				return errors.WithStack(err)
			}
		}
	case dml.ColumnMapScan:
		if cm.Count == 0 {
			cc.Data = cc.Data[:0]
		}
		e := new(ViewCustomerAutoIncrement)
		if err := cc.scanColumns(cm, e, cm.Count); err != nil {
			return errors.WithStack(err)
		}
		cc.Data = append(cc.Data, e)
	case dml.ColumnMapCollectionReadSet:
		for cm.Next() {
			switch c := cm.Column(); c {
			default:
				return errors.NotFound.Newf("[dmltestgenerated] ViewCustomerAutoIncrements Column %q not found", c)
			}
		} // end for cm.Next

	default:
		return errors.NotSupported.Newf("[dmltestgenerated] Unknown Mode: %q", string(m))
	}
	return cm.Err()
}

func (cc *ViewCustomerAutoIncrements) DBLoad(ctx context.Context, dbm *DBM, pkIDs []uint32, opts ...dml.DBRFunc) (err error) {
	ctx, span := dbm.option.Trace.Start(ctx, "ViewCustomerAutoIncrementsDBLoad")
	defer func() { cstrace.Status(span, err); span.End() }()
	if cc == nil {
		return errors.NotValid.Newf("ViewCustomerAutoIncrement can't be nil")
	}
	// put the IDs CeEntityID into the context as value to search for a cache entry in the event function.
	if err = dbm.eventViewCustomerAutoIncrementFunc(ctx, dml.EventFlagBeforeSelect, cc, nil); err != nil {
		return errors.WithStack(err)
	}
	if cc.Data != nil {
		return nil // might return data from cache
	}
	if len(pkIDs) > 0 {
		if _, err = dbm.CachedQuery("ViewCustomerAutoIncrementsSelectByPK").ApplyCallBacks(opts...).Load(ctx, cc, pkIDs); err != nil {
			return errors.WithStack(err)
		}
	} else {
		if _, err = dbm.CachedQuery("ViewCustomerAutoIncrementsSelectAll").ApplyCallBacks(opts...).Load(ctx, cc); err != nil {
			return errors.WithStack(err)
		}
	}
	return errors.WithStack(dbm.eventViewCustomerAutoIncrementFunc(ctx, dml.EventFlagAfterSelect, cc, nil))
}

// Delete will remove an item from the slice. Auto generated via dmlgen.
func (cc *ViewCustomerAutoIncrements) Delete(i int) *ViewCustomerAutoIncrements {
	z := cc.Data // copy the slice header
	end := len(z) - 1
	cc.Swap(i, end)
	copy(z[i:], z[i+1:])
	z[end] = nil // this should avoid the memory leak
	z = z[:end]
	cc.Data = z
	return cc
}

// Each will run function f on all items in []* ViewCustomerAutoIncrement . Auto
// generated via dmlgen.
func (cc *ViewCustomerAutoIncrements) Each(f func(*ViewCustomerAutoIncrement)) *ViewCustomerAutoIncrements {
	if cc == nil {
		return nil
	}
	for i := range cc.Data {
		f(cc.Data[i])
	}
	return cc
}

// Filter filters the current slice by predicate f without memory allocation.
// Auto generated via dmlgen.
func (cc *ViewCustomerAutoIncrements) Filter(f func(*ViewCustomerAutoIncrement) bool) *ViewCustomerAutoIncrements {
	if cc == nil {
		return nil
	}
	b, i := cc.Data[:0], 0
	for _, e := range cc.Data {
		if f(e) {
			b = append(b, e)
		}
		i++
	}
	for i := len(b); i < len(cc.Data); i++ {
		cc.Data[i] = nil // this should avoid the memory leak
	}
	cc.Data = b
	return cc
}

// Insert will place a new item at position i. Auto generated via dmlgen.
func (cc *ViewCustomerAutoIncrements) Insert(n *ViewCustomerAutoIncrement, i int) *ViewCustomerAutoIncrements {
	z := cc.Data // copy the slice header
	z = append(z, &ViewCustomerAutoIncrement{})
	copy(z[i+1:], z[i:])
	z[i] = n
	cc.Data = z
	return cc
}

// Swap will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *ViewCustomerAutoIncrements) Swap(i, j int) { cc.Data[i], cc.Data[j] = cc.Data[j], cc.Data[i] }

// Len will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *ViewCustomerAutoIncrements) Len() int {
	if cc == nil {
		return 0
	}
	return len(cc.Data)
}

// Validate runs internal consistency tests on all items.
func (cc *ViewCustomerAutoIncrements) Validate() (err error) {
	if len(cc.Data) == 0 {
		return nil
	}
	for i, ld := 0, len(cc.Data); i < ld && err == nil; i++ {
		err = cc.Data[i].Validate()
	}
	return
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (cc *ViewCustomerAutoIncrements) WriteTo(w io.Writer) (n int64, err error) {
	for i, d := range cc.Data {
		n2, err := d.WriteTo(w)
		if err != nil {
			return 0, errors.Wrapf(err, "[dmltestgenerated] WriteTo failed at index %d", i)
		}
		n += n2
	}
	return n, nil
}

// ViewCustomerNoAutoIncrement represents a single row for DB table
// view_customer_no_auto_increment. Auto generated.
// Table comment: VIEW
//easyjson:json
type ViewCustomerNoAutoIncrement struct {
	Email     null.String `max_len:"255"` // email varchar(255) NULL  DEFAULT 'NULL'  "Email"
	Firstname string      `max_len:"255"` // firstname varchar(255) NOT NULL    "First Name"
	Lastname  string      `max_len:"255"` // lastname varchar(255) NOT NULL    "Last Name"
	City      string      `max_len:"255"` // city varchar(255) NOT NULL    "City"
}

// Copy copies the struct and returns a new pointer. TODO use deepcopy tool to
// generate code afterwards
func (e *ViewCustomerNoAutoIncrement) Copy() *ViewCustomerNoAutoIncrement {
	e2 := new(ViewCustomerNoAutoIncrement)
	*e2 = *e // for now a shallow copy
	return e2
}

// MapColumns implements interface ColumnMapper only partially. Auto generated.
func (e *ViewCustomerNoAutoIncrement) MapColumns(cm *dml.ColumnMap) error {
	if cm.Mode() == dml.ColumnMapEntityReadAll {
		return cm.NullString(&e.Email).String(&e.Firstname).String(&e.Lastname).String(&e.City).Err()
	}
	for cm.Next() {
		switch c := cm.Column(); c {
		case "email":
			cm.NullString(&e.Email)
		case "firstname":
			cm.String(&e.Firstname)
		case "lastname":
			cm.String(&e.Lastname)
		case "city":
			cm.String(&e.City)
		default:
			return errors.NotFound.Newf("[dmltestgenerated] ViewCustomerNoAutoIncrement Column %q not found", c)
		}
	}
	return errors.WithStack(cm.Err())
}

// The table/view ViewCustomerNoAutoIncrement does not have a primary key.
// SKipping to generate DML functions based on the PK.

// Empty empties all the fields of the current object. Also known as Reset.
func (e *ViewCustomerNoAutoIncrement) Empty() *ViewCustomerNoAutoIncrement {
	*e = ViewCustomerNoAutoIncrement{}
	return e
}

// This variable can be set in another file to provide a custom validator.
var validateViewCustomerNoAutoIncrement func(*ViewCustomerNoAutoIncrement) error

// Validate runs internal consistency tests.
func (e *ViewCustomerNoAutoIncrement) Validate() error {
	if e == nil {
		return errors.NotValid.Newf("Type %T cannot be nil", e)
	}
	if validateViewCustomerNoAutoIncrement != nil {
		return validateViewCustomerNoAutoIncrement(e)
	}
	return nil
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (e *ViewCustomerNoAutoIncrement) WriteTo(w io.Writer) (n int64, err error) {
	// for now this printing is good enough. If you need better swap out with your code.
	n2, err := fmt.Fprint(w,
		"email:", e.Email, "\n",
		"firstname:", e.Firstname, "\n",
		"lastname:", e.Lastname, "\n",
		"city:", e.City, "\n",
	)
	return int64(n2), err
}

// ViewCustomerNoAutoIncrements represents a collection type for DB table
// view_customer_no_auto_increment
// Not thread safe. Auto generated.
//easyjson:json
type ViewCustomerNoAutoIncrements struct {
	Data []*ViewCustomerNoAutoIncrement `json:"data,omitempty"`
}

// NewViewCustomerNoAutoIncrements  creates a new initialized collection. Auto
// generated.
func NewViewCustomerNoAutoIncrements() *ViewCustomerNoAutoIncrements {
	return &ViewCustomerNoAutoIncrements{
		Data: make([]*ViewCustomerNoAutoIncrement, 0, 5),
	}
}

// Append will add a new item at the end of * ViewCustomerNoAutoIncrements . Auto
// generated via dmlgen.
func (cc *ViewCustomerNoAutoIncrements) Append(n ...*ViewCustomerNoAutoIncrement) *ViewCustomerNoAutoIncrements {
	cc.Data = append(cc.Data, n...)
	return cc
}

// UnmarshalBinary implements encoding.BinaryUnmarshaler.
func (cc *ViewCustomerNoAutoIncrements) UnmarshalBinary(data []byte) error {
	return cc.Unmarshal(data) // Implemented via github.com/gogo/protobuf
}

// MarshalBinary implements encoding.BinaryMarshaler.
func (cc *ViewCustomerNoAutoIncrements) MarshalBinary() (data []byte, err error) {
	return cc.Marshal() // Implemented via github.com/gogo/protobuf
}

// Cut will remove items i through j-1. Auto generated via dmlgen.
func (cc *ViewCustomerNoAutoIncrements) Cut(i, j int) *ViewCustomerNoAutoIncrements {
	z := cc.Data // copy slice header
	copy(z[i:], z[j:])
	for k, n := len(z)-j+i, len(z); k < n; k++ {
		z[k] = nil // this avoids the memory leak
	}
	z = z[:len(z)-j+i]
	cc.Data = z
	return cc
}

func (cc *ViewCustomerNoAutoIncrements) scanColumns(cm *dml.ColumnMap, e *ViewCustomerNoAutoIncrement, idx uint64) error {
	if err := e.MapColumns(cm); err != nil {
		return errors.WithStack(err)
	}
	// this function might get extended.
	return nil
}

// MapColumns implements dml.ColumnMapper interface. Auto generated.
func (cc *ViewCustomerNoAutoIncrements) MapColumns(cm *dml.ColumnMap) error {
	switch m := cm.Mode(); m {
	case dml.ColumnMapEntityReadAll, dml.ColumnMapEntityReadSet:
		for i, e := range cc.Data {
			if err := cc.scanColumns(cm, e, uint64(i)); err != nil {
				return errors.WithStack(err)
			}
		}
	case dml.ColumnMapScan:
		if cm.Count == 0 {
			cc.Data = cc.Data[:0]
		}
		e := new(ViewCustomerNoAutoIncrement)
		if err := cc.scanColumns(cm, e, cm.Count); err != nil {
			return errors.WithStack(err)
		}
		cc.Data = append(cc.Data, e)
	case dml.ColumnMapCollectionReadSet:
		for cm.Next() {
			switch c := cm.Column(); c {
			default:
				return errors.NotFound.Newf("[dmltestgenerated] ViewCustomerNoAutoIncrements Column %q not found", c)
			}
		} // end for cm.Next

	default:
		return errors.NotSupported.Newf("[dmltestgenerated] Unknown Mode: %q", string(m))
	}
	return cm.Err()
}

// The table/view ViewCustomerNoAutoIncrements does not have a primary key.
// Skipping to generate DML functions based on the PK.

// Delete will remove an item from the slice. Auto generated via dmlgen.
func (cc *ViewCustomerNoAutoIncrements) Delete(i int) *ViewCustomerNoAutoIncrements {
	z := cc.Data // copy the slice header
	end := len(z) - 1
	cc.Swap(i, end)
	copy(z[i:], z[i+1:])
	z[end] = nil // this should avoid the memory leak
	z = z[:end]
	cc.Data = z
	return cc
}

// Each will run function f on all items in []* ViewCustomerNoAutoIncrement .
// Auto generated via dmlgen.
func (cc *ViewCustomerNoAutoIncrements) Each(f func(*ViewCustomerNoAutoIncrement)) *ViewCustomerNoAutoIncrements {
	if cc == nil {
		return nil
	}
	for i := range cc.Data {
		f(cc.Data[i])
	}
	return cc
}

// Filter filters the current slice by predicate f without memory allocation.
// Auto generated via dmlgen.
func (cc *ViewCustomerNoAutoIncrements) Filter(f func(*ViewCustomerNoAutoIncrement) bool) *ViewCustomerNoAutoIncrements {
	if cc == nil {
		return nil
	}
	b, i := cc.Data[:0], 0
	for _, e := range cc.Data {
		if f(e) {
			b = append(b, e)
		}
		i++
	}
	for i := len(b); i < len(cc.Data); i++ {
		cc.Data[i] = nil // this should avoid the memory leak
	}
	cc.Data = b
	return cc
}

// Insert will place a new item at position i. Auto generated via dmlgen.
func (cc *ViewCustomerNoAutoIncrements) Insert(n *ViewCustomerNoAutoIncrement, i int) *ViewCustomerNoAutoIncrements {
	z := cc.Data // copy the slice header
	z = append(z, &ViewCustomerNoAutoIncrement{})
	copy(z[i+1:], z[i:])
	z[i] = n
	cc.Data = z
	return cc
}

// Swap will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *ViewCustomerNoAutoIncrements) Swap(i, j int) {
	cc.Data[i], cc.Data[j] = cc.Data[j], cc.Data[i]
}

// Len will satisfy the sort.Interface. Auto generated via dmlgen.
func (cc *ViewCustomerNoAutoIncrements) Len() int {
	if cc == nil {
		return 0
	}
	return len(cc.Data)
}

// Validate runs internal consistency tests on all items.
func (cc *ViewCustomerNoAutoIncrements) Validate() (err error) {
	if len(cc.Data) == 0 {
		return nil
	}
	for i, ld := 0, len(cc.Data); i < ld && err == nil; i++ {
		err = cc.Data[i].Validate()
	}
	return
}

// WriteTo implements io.WriterTo and writes the field names and their values to
// w. This is especially useful for debugging or or generating a hash of the
// struct.
func (cc *ViewCustomerNoAutoIncrements) WriteTo(w io.Writer) (n int64, err error) {
	for i, d := range cc.Data {
		n2, err := d.WriteTo(w)
		if err != nil {
			return 0, errors.Wrapf(err, "[dmltestgenerated] WriteTo failed at index %d", i)
		}
		n += n2
	}
	return n, nil
}
